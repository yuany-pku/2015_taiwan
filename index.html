<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
<head>
   <META http-equiv=Content-Type content="text/html; charset=gb2312">
   <title>2015 Taiwan Short Course on Mathematical Introduction to Data Science</title>
</head>
<body background="../images/crysback.jpg">

<!-- PAGE HEADER -->

<div class="Section1">
<table border="0" cellpadding="0" width="100%" style="width: 100%;">
      <tbody>
        <tr>

       <td style="padding: 0.75pt;" width="200" align="center">

      <p class="MsoNormal">&nbsp;
       <img width="64" height="64"
 id="_x0000_i1025"
 src="NCTU.gif" alt="PKU">
      <img width="64" height="64"
 id="_x0000_i1025"
 src="NCU.png" alt="PKU">
 <img width="64" height="64"
 id="_x0000_i1025"
 src="National_Taiwan_University_Logo.jpg" alt="PKU">
          </p>
       </td>
       <td style="padding: 0.75pt;">
      <p>
<span style="font-size: 18pt;">
<b><big>Taiwan Short Course: Mathematical Introduction of Data Analysis<br>
   May 2015</big></b>
<br>
</p>
</td>
</tr>

</tbody>
</table>

<div class="MsoNormal" align="center" style="text-align: center;">
<hr size="2" width="100%" align="center">  </div>

<ul type="disc">

</ul>

<!-- COURSE INFORMATION BANNER -->

<table border="0" cellpadding="0" width="100%" bgcolor="#990000"
 style="background: rgb(153,0,0) none repeat scroll 0% 50%; width: 100%;">
      <tbody>

        <tr>
       <td style="padding: 2.25pt;">
      <p class="MsoNormal"><b><span
 style="font-size: 13.5pt; color: white;">Course Information</span></b></p>
       </td>
      </tr>

  </tbody>
</table>

<!-- COURSE INFORMATION -->

<h3>Synopsis (&#25688;&#35201;)</h3>
<p style="margin-left: 0.5in;">
<big>
 [<a href="http://pan.baidu.com/s/1eQ91yQQ">Poster</a>]
 <p>
 <ul>
<li> Maximum likelihood estimator: Sample mean and PCA; Stein's phenomenon and shrinkage in high dimensional statistics; </li>
<li>random projection and compressed sensing; extended PCAs: robust PCA, sparse PCA, and MDS with uncertainty; </li>
<li>manifold learning; topological data analysis</li>
</ul>
</big>
</p>



<h3>Schedule:</h3>

                              <table border="1" cellspacing="0"><tbody><tr>
<td align="left"><strong>Time/Venue</strong></td>
<td align="left"><strong>Slides</strong></td>
</tr>

<tr>
<td>Thu, 04/30/2015, 4-5pm, NCTU <p><img width="64" height="64"
 id="_x0000_i1025"
 src="NCTU.gif" alt="PKU"></td>
<td>Lecture 0: Introduction [<a href="http://pan.baidu.com/s/1bn6PKj9">slides</a>]
</td>
</tr>

<tr>
<td>Fri, 05/01/2015, 4-5pm, NCTS-NTU <p><img width="64" height="64"
 id="_x0000_i1025"
 src="National_Taiwan_University_Logo.jpg" alt="PKU">
 </td>
<td>Seminar 1: A Dynamica Approach to Sparse Recovery [<a href="http://pan.baidu.com/s/1bn6PKj9">slides</a>]
<ul>Abstract: In this talk we aim to solve an open problem raised by Jianqing Fan et al. in 2001, where convex l1-regularization (LASSO) causes bias in linear regression and nonconvex regularization is thus introduced for debias which however suffers from NP-hardness in finding global optimizers. We show a novel approach utilizing a technique from dynamics. Instead of optimizing a potential (objective) function, we evolve ODEs formed by gradient descent in dual space of $l_1$-norm. Equipped with early stopping regularization, it simultaneously achieves variable selection consistency and unbiased estimator, which is thus better than LASSO estimator. The dynamics leads to a simple discretization as linearized Bregman iteration algorithm, which has been widely used in image processing, matrix completion, as well as robust ranking, etc.
</ul>
</td>
</tr>

<tr>
<td>Tue, 05/05/2015, 3-5pm, <p> 107 Hung-Ching Bldg, NCU<p>
<img width="64" height="64"
 id="_x0000_i1025"
 src="NCU.png" alt="PKU">
    </td>
<td>Lecture 1: MDS/PCA and High Dimensionality [<a href="http://pan.baidu.com/s/1bn6PKj9">slides</a>]
    </td>
    </tr>

<tr>
<td>Wed, 05/06/2015, 3-5pm, <p> 107 Hung-Ching Bldg, NCU<p>
<img width="64" height="64"
 id="_x0000_i1025"
 src="NCU.png" alt="PKU">
    </td>
<td>Lecture 2: Generalized MDS/PCA [<a href="http://pan.baidu.com/s/1bn6PKj9">slides</a>]
    </td>
    </tr>
    
 <tr>
<td>Thu, 05/07/2015, 3-5pm, <p> 107 Hung-Ching Bldg, NCU<p>
<img width="64" height="64"
 id="_x0000_i1025"
 src="NCU.png" alt="PKU">
    </td>
<td>Lecture 3: Geometric and Topological Data Analysis [<a href="http://pan.baidu.com/s/1bn6PKj9">slides</a>]
    </td>
    </tr>



<tr>
<td>Fri, 05/08/2015, 4-5pm, NCTS-NTU <p> <img width="64" height="64"
 id="_x0000_i1025"
 src="National_Taiwan_University_Logo.jpg" alt="PKU">
 </td>
<td>Seminar 2: Applied Hodge Theory [<a href="http://pan.baidu.com/s/1bn6PKj9">slides</a>]
<ul>Hodge Theory is a milestone bridging differential geometry and algebraic topology. It studies certain functions (called forms) on data rather than data points themselves, and brings an optimization perspective to decompose such functions adaptive to the underlying topology. Recently Hodge Theory inspires rising applications in computer vision, multimedia, statistical ranking, game and voting theory, in addition to traditional applications in mechanics etc. In this talk we give an introduction to Hodge Theory with examples in these applications.
</ul>
</td>
</tr>

</body>
</html>

