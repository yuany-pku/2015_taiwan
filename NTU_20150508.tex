%!TEX encoding = UTF-8 Unicode
\documentclass[slidestop,compress,epsfig,color]{beamer}
\usepackage{pstricks}
\usepackage{graphicx}
\usepackage{amsmath,amssymb,amsthm,amsfonts}
%\usepackage{beamerthemesplit}
\usetheme{Warsaw}
\mode<presentation> 
\useoutertheme{shadow} 
\useoutertheme{miniframes} %miniframes
%\useoutertheme[subsection=false]{smoothbars} 
\useinnertheme{rectangles}
\usepackage{CJKutf8}

%\beamersetuncovermixins{\opaqueness<1>{25}}{\opaqueness<2->{15}}

\providecommand{\R}{\mathbb{R}}
\providecommand{\X}{\mathcal{X}}
\providecommand{\Y}{\mathcal{Y}}
\providecommand{\Z}{\mathcal{Z}}
\providecommand{\E}{\mathbb{E}}
\providecommand{\H}{\mathcal{H}}
\providecommand{\D}{\mathcal{D}}
\providecommand{\U}{\mathcal{U}}
\providecommand{\De}{\Delta}
\providecommand{\de}{\delta}
\providecommand{\hg}{\hat{g}}
\providecommand{\1}{\mathbf{1}}
\providecommand{\NN}{\mathcal{N}}
\providecommand{\X}{\mathcal{X}}
\providecommand{\Y}{\mathcal{Y}}
\providecommand{\E}{\mathbb{E}}
\providecommand{\H}{\mathcal{H}}
\providecommand{\D}{\mathcal{D}}
\providecommand{\U}{\mathcal{U}}
\providecommand{\De}{\Delta}
\providecommand{\de}{\delta}
\providecommand{\hg}{\hat{g}}
\providecommand{\ga}{\gamma}
\providecommand{\la}{\lambda}


\theoremstyle{example}
\newtheorem{thm}{}
%\newtheorem{fact}{}

\providecommand{\subitem}{\\ \textcolor{yellow}{$\bullet\ $}}
\DeclareMathOperator{\sign}{sign}
%\DeclareMathOperator{\span}{span}
\DeclareMathOperator{\diag}{diag}
\DeclareMathOperator{\supp}{supp}
%\DeclareMathOperator{\ker}{ker}
\DeclareMathOperator{\im}{im}
\DeclareMathOperator{\proj}{proj}
\DeclareMathOperator{\grad}{grad}
\DeclareMathOperator{\curl}{curl}
\DeclareMathOperator{\dive}{div}
\DeclareMathOperator{\ASL}{\mathfrak{sl}}



\title[Applied Hodge Theory]{Applied Hodge Theory}
\author{Yuan Yao}
\institute{School of Mathematical Sciences \\ Peking University}
\date{May 8, 2015}
\addtobeamertemplate{title page}{}{}

\begin{document}

\frame{\titlepage}

%\frame{
%\frametitle{Topological \& Geometric Methods in Data Analysis}
%\begin{itemize}
%\item Differential Geometric methods: \textcolor{blue}{manifolds}
%\subitem data distribution: manifold learning/NDR, etc.
%\subitem model space: information geometry (high-order efficiency for parametric statistics), Grassmannian, etc.
%\item Algebraic Geometric methods: \textcolor{blue}{polynomials/varieties}
%\subitem tensor, Sum-Of-Square (MDS, polynom. optim.), etc
%\subitem algebraic statistics
%\item Algebraic Topological methods: \textcolor{blue}{complexes (graphs, etc.)}
%\subitem persistent homology (robust, slow)
%\subitem Euler calculus (non-stable, fast)
%\subitem \textcolor{red}{Hodge theory} (geometry$\leftrightarrow$topology via optimization or spectral method)
%\end{itemize}
%}

\section[Outline]{}
\frame{\tableofcontents}

\section[Hodge Theory]{What's Hodge Theory}

\frame{
\frametitle{Helmholtz-Hodge Decomposition}
\begin{theorem}[c.f. Marsden-Chorin 1992] A vector field $\bf{w}$ on a simply-connected $D$ can be uniquely decomposed in the form
\[ {\bf{w}} = {\bf{u}} + \grad \phi \]
where $\bf{u}$ has zero divergence and is parallel to $\partial D$. 
\end{theorem}
\begin{figure}[!h]
\centering
\includegraphics[width=0.4\textwidth]{figures/Helmholtz-hodge.png} \ \ \ \ 
\includegraphics[width=0.2\textwidth]{figures/Chorin-Marsden.png}
%\caption{Courtesy by Anil Hirani}
  \end{figure} 
  }
  
\subsection{Hodge Theory in Linear Algebra}
\frame{
	\frametitle{Hodge Theory in Linear Algebra}%
	For inner product spaces $\X$, $\Y$, and $\Z$, consider	
	\[
	\X \xrightarrow{A} \Y \xrightarrow{B} \Z.
	\]
	and $\Delta =A A^\ast + B^\ast B: \Y\to \Y$ where $(\cdot )^\ast$ is adjoint operator of $(\cdot)$.
	
	If 
	\[ \textcolor{red}{B \circ A = 0},\]
	then $\ker(\Delta) = \ker(A^\ast) \cap \ker(B)$ and \emph{orthogonal} decomposition   
	\[ \Y = \textcolor{green}{\im (A)} + \textcolor{brown}{\ker(\Delta)} + \textcolor{blue}{\im (B^\ast)} \]
	Note: $\textcolor{blue}{\ker(B)/\im(A)}\simeq \ker(\Delta)$ is the (real) (co)-homology group ($\R\to$ rings; vector spaces$\rightarrow$module).
%	Note: let $V=\X \oplus \Y\oplus \Z$ and $D=diag(A,B,0)$. 
	}
	
\frame{
	\frametitle{Hodge Decomposition=Rank-Nullity Theorem}%
	Take product space $V=\X\times\Y\times\Z$, define	
	\[
	D = \left( 
	\begin{array}{ccc}
	0 & 0 & 0 \\
	A & 0 & 0 \\
	0 & B & 0
	\end{array}
	\right), \ \ \ BA = 0,
	\]
	\textcolor{red}{Laplacian} 
	$$L=(D+D^\ast)^2=\diag(A^\ast A, AA^\ast+B^\ast B, BB^\ast)=\diag(L_0,L_1,L_2^{(down)})$$
	\textcolor{red}{Rank-nullity Theorem}: $\im(D) + \ker(D^\ast) = V$, in particular
	\begin{eqnarray*}
	\Y & = & \im(A) + \ker(A^\ast) \\
	& = & \im(A) + \ker(A^\ast)/\im(B^\ast) + \im(B^\ast), \mbox{since $\im(A)\subseteq\ker(B)$} \\
	& = & \im(A) + \ker(A^\ast)\cap \ker(B) + \im(B^\ast) 
	\end{eqnarray*}
	}

\frame{
	\frametitle{Terminology}
	\begin{itemize}
	\item \textcolor{blue}{coboundary maps}: $A:\X\to \Y$, $B : \Y\to \Z$
	\item \textcolor{blue}{cochains}: elements in $\X$, $\Y$, $\Z$
	\item \textcolor{blue}{cochain complex}:$\X \xrightarrow{A} \Y \xrightarrow{B} \Z$.
	\item \textcolor{blue}{cocycles}: elements of $\ker(A)$
	\item \textcolor{blue}{coboundaries}: elements of $\im(B)$
	\item \textcolor{blue}{cohomology classes}: elements of $\ker(A)/\im(B)$ 
	\item \textcolor{blue}{harmonic cochains}: elements of $\ker(A^\ast A + BB^\ast)$ 
	\item \textcolor{blue}{Betti number}: $\dim \ker(A^\ast A + BB^\ast)$
	\item \textcolor{blue}{closed}: $Ax = 0$ 
	\item \textcolor{blue}{exact}: $x = Bz$
	\end{itemize}
}	

\subsection{Hodge Theory on Riemannian Manifolds}

\frame{
\frametitle{Classical Hodge Theory on Riemannian Manifolds}
\begin{itemize}
\item (\textcolor{blue}{W.V.D. Hodge}, 1903-1975) de Rham complex: % $d^2=d_k \circ d_{k-1}=0$
\[ 0\to \Omega^0(M) \xrightarrow{d_0} \Omega^1(M) \xrightarrow{d_1} \cdots \xrightarrow{d_{n-1}} \Omega^n(M)\xrightarrow{d_n} 0\]
%\item There are more, e.g. Hodge Theory on Sheafs (Joe Friedman). 
\subitem $M$: compact Riemannian manifold
 \subitem $\Omega^k(M)$: with $k$-differential forms  
 \subitem $d$: the exterior derivative%whose adjoint, codifferential operator $\delta$ satisfies $\left< d u, v\right>=\left< u , \delta v\right>$ 
 \[ d^2=d_k \circ d_{k-1}=0\]
\end{itemize}
%\begin{figure}[!h]
%\centering
%\includegraphics[width=0.3\textwidth]{figures/Ozdaglar.png} 
%\caption{Courtesy by Asu Ozdaglar}
%  \end{figure} 
}


\subsection{Hodge Theory on Metric Spaces}
\frame{
\frametitle{Hodge Theory on Metric Spaces}
\begin{itemize}
\item (Alexander-Spanier, \textcolor{blue}{Bartholdi-Schick-Smale-Smale, 2011}) %complex, $d^2 =0$
\[ 0\to L^2(X) \xrightarrow{d_0} L^2(X^2) \xrightarrow{d_1} \cdots \xrightarrow{d_{n-1}} L^2(X^n)\xrightarrow{d_n} \cdot \]
%\item There are more, e.g. Hodge Theory on Sheafs (Joe Friedman). 
\subitem $X$: metric space
\subitem $L^2(X)$: square integral functions on $X$
\subitem $d: L^2(X^{k})\to L^2(X^{k+1})$, finite difference %(Gilboa-Osher'08) 
\[ (d f) (x_0,\ldots,x_k) = \sum_{i=1}^k (-1)^i \prod_{j\neq i} \sqrt{K(x_i,x_j)} f(x_{-i}) \]
\subitem adjoint operator $\delta: L^2(X^{k+1}) \to L^2(X^k)$
\[ \delta g(x) = \sum_{i=0}^k (-1)^i \int_X \prod_{j=0}^{k-1} \sqrt{K(t,x_j)} g(x_0,\ldots,x_{i-1},t,x_{i},\ldots,x_{k-1}) dt \]
\end{itemize}
%\begin{figure}[!h]
%\centering
%\includegraphics[width=0.3\textwidth]{figures/Ozdaglar.png} 
%\caption{Courtesy by Asu Ozdaglar}
%  \end{figure} 
}


%\frame{
%\frametitle{continued: Hodge Theory on Metric Spaces}
%\begin{thm}[Bartholdi-Schick-Smale-Smale-Baker, 2011]
%If $X$ satisfies some regularity conditions, then Hodge decomposition holds 
%\[ L^2(X^k) = \im (d_{k-1}) \oplus \ker(\Delta_k) \oplus \im(\delta_k) \]
%In particular, if $X$ is a compact Riemannian manifold with regularity conditions on convexity and curvature, there is a scale/kernel such that 
%$\ker(\Delta_k)$ is isomorphic to the $L^2$-cohomology and de Rham cohomology. 
%\end{thm}
%
%\begin{itemize}
%\item $\Delta=d \delta+ \delta d$
%\item for finite $X$, it essentially builds up a \v{C}ech complex for point cloud data at certain scale and applies combinatorial Hodge theory
%\end{itemize}
%}

\subsection{Combinatorial Hodge Theory on Simplicial Complexes}
\frame{
\frametitle{Combinatorial Hodge Theory on Simplicial Complexes}
\[ 0\to \Omega^0(X) \xrightarrow{d_0} \Omega^1(X) \xrightarrow{d_1} \cdots \xrightarrow{d_{n-1}} \Omega^n(X)\xrightarrow{d_n} \cdots\]

\begin{itemize}
\item $X$ is finite
\item $\chi (X)\subseteq 2^X$: \textcolor{red}{simplicial complex} formed by $X$ $\Leftrightarrow$ if $\tau\in \chi (X)$ and $\sigma\subseteq \tau$, then $\sigma\in \chi(X)$ 
\item  \textcolor{red}{$k$-forms or cochains} as alternating functions \[
	\Omega^{k}(X)=\{u:\chi_{k+1}(X)\rightarrow
	\mathbb{R},u_{i_{\sigma(0)},\dots,i_{\sigma(k)}}=\operatorname*{sign}%
	(\sigma)u_{i_{0},\ldots,i_{k}}\}
	\]
	%where $\sigma \in\mathfrak{S}_{k+1}$ is a permutation on $(0,\dots,k)$.
\item \textcolor{red}{coboundary maps} $d_k : \Omega^k(X) \to \Omega^{k+1}(X)$ alternating difference 
	  \[ (d_k u)(i_0,\ldots,i_{k+1}) = \sum_{j=0}^{k+1} (-1)^{j+1} u(i_0,\ldots,i_{j-1},i_{j+1},\ldots,i_{k+1}) \]
	  \item  $d_k\circ d_{k-1} =0$
\end{itemize}
}

\frame{

	  \frametitle{Example: graph and clique complex}
	   
	  \begin{itemize}
	  \item $G=(X,E)$ is a undirected but oriented graph
	  \item Clique complex $\chi_G\subseteq 2^X$ collects all complete subgraph of $G$
	  \item  $k$-forms or cochains $\Omega^{k}(\chi_G)$ as alternating functions:	  
	  \subitem \textcolor{red}{0-forms}: $v:V\to \R \cong \R^{n}$
	  \subitem \textcolor{red}{1-forms as skew-symmetric functions}: $w_{ij}=-w_{ji}$
	  \subitem \textcolor{red}{2-forms as triangular-curl}: $z_{ijk} = z_{jki}=z_{kij}=-z_{jik}=-z_{ikj}=-z_{kji}$
	\item coboundary operators as alternating difference operators:
	  \subitem $(d_{0} v) (i,j)= v_{j} - v_{i}=:(\operatorname*{\textcolor{red}{grad}} v)(i,j)$
	  \subitem  $(d_{1} w) (i,j,k) = (\pm)( w_{ij}+ w_{jk} + w_{ki})=:(\operatorname*{\textcolor{red}{curl}} w)(i,j,k)$ 
%	  \item Adjoints induced by metrics/inner products on $\Omega^{k}(\chi_G)$:
%	  \subitem $(\operatorname**{\textcolor{red}{div}} w)(i) := - (d_{0}^{\ast} w )(i) := \sum w_{i\ast}  $
	  \item \textcolor{red}{$d_1 \circ d_0 = \curl(\grad u)= 0$}
	  \end{itemize}   
}

\frame{
\frametitle{Hodge Laplacian}
\begin{itemize}
%\item adjoint $\delta = d^\ast$ depending on the inner product on $\Omega^k(X)$
\item combinatorial Laplacian $\Delta = d_{k-1} d_{k-1}^\ast + d_k^\ast d_k$
\subitem $k=0$, $\Delta_0 = d_0^\ast d_0$ is the (unnormalized) \textcolor{red}{graph Laplacian}
\subitem $k=1$, 1-Hodge Laplacian (Helmholtzian)
	\[ \textcolor{red}{\Delta_1 = \curl \circ \curl^\ast - \dive \circ \grad} \]
\item Hodge decomposition holds for $\Omega^k(X)$
\subitem \textcolor{red}{$\Omega^k(X)=\im (d_{k-1}) \oplus \ker(\Delta_k) \oplus \im(\delta_k) $}
\subitem $\dim(\Delta_k) = \beta_k(\chi(X))$ 
\end{itemize}
\begin{figure}[!h]
\centering
\includegraphics[width=0.3\textwidth]{figures/Ozdaglar.png} 
\caption{Courtesy by Asu Ozdaglar}
  \end{figure} 

}

\section[Social Choice/Preference Aggregation]{Social Choice vs. Hodge Theory}

%\frame{
%  \frametitle{Fundamental problem of preference aggregation} 
%  \textcolor{red}{How to aggregate preferences which faithfully represent individuals?}
%  \begin{figure}[!h]
%	\centering
%	\includegraphics[width=0.7\textwidth]{figures/voting.jpeg}
%%	\caption{(Xu-Huang-Y., et al. 11) Crowdsouring subjective Quality of Experience evaluation}
%	\end{figure} 
%}

\frame{
  \frametitle{Social Choice Problem}
  \begin{center}
  \textcolor{red}{How to aggregate preferences \\ which faithfully represent individuals?}
  \end{center}
%\begin{itemize}
%\item \textcolor{red}{How to aggregate preferences which faithfully represent individuals?}
%\item Classical social choice theory origins from Voting Theory
%\subitem \emph{Borda} 1770, B. Count against plurality vote 
%\subitem \emph{Condorcet} 1785, C. Winner who wins all paired elections 
%\subitem Impossibility theorems: \emph{Kenneth Arrow} 1963, \emph{Amartya Sen} 1973
%\subitem Resolving conflicts: \emph{Kemeny}, \emph{Saari} ...  
%%\item Internet provides us a plethora of new examples
%%\subitem Recommendation systems (Amazon, netflix, ...)
%%\subitem Peer review systems (CiteSeer, Google's pagerank, eBay, ...)
%%\subitem Crowdsourced ranking ({\tt{allourideas}, \tt{crowdrank}}, ...)
%\item Modern crowdsourcing ranking/voting ...
%\end{itemize}
}

\frame{
	\frametitle{Crowdsourcing QoE evaluation of Multimedia}
	\begin{figure}[!h]
	\centering
	\includegraphics[width=0.7\textwidth]{figures/crowdsourcing2.png}
	\caption{(Xu-Huang-Y., et al. 11) Crowdsouring subjective Quality of Experience evaluation}
	\end{figure} 
}


\frame{
	\frametitle{Crowdsourcing ranking}
	\begin{figure}[!t]
	\centering
	\includegraphics[width=0.6\textwidth]{./figures/allourideas-wikipedia.png}  \ \ 
	\includegraphics[width=0.3\textwidth]{./figures/CrowdRank.pdf}  
	\caption{Left: www.\textcolor{red}{allourideas}.org/wikipedia-banner-challenge, by Prof. Matt Salganik at Princeton; Right: www.\textcolor{red}{crowdrank}.net}
  \end{figure} 
	}

%\frame{
%	\frametitle{Relative attributes in describing objects}
%	\begin{figure}[!t]
%	\centering
%	\includegraphics[width=0.7\textwidth]{./figures/horse-vs-donkey.png}  
%	\caption{(Parikh-Grauman'11) Horse vs. Donkey: furry (donkey $>$ horse), long tails (horse $>$ donkey), running faster (horse $>$ donkey), cute(?)}
%  \end{figure} 
%	}

\frame{
	\frametitle{Learning relative attributes: age}
	\begin{figure}[!t]
	\centering
	\includegraphics[width=\textwidth]{./figures/idea_illustration.eps}  
	\caption{Age: a relative attribute estimated from paired comparisons (Fu-Y.-Xiang et al. 2014)}
  \end{figure} 
	}
	
	
%\frame{
%\frametitle{Thurstone's Crime Scaling in 1928 }
%
%  \begin{figure}[!h]
%\centering
%\includegraphics[width=0.8\textwidth]{figures/thurstone.png} 
%\caption{Can we learn a scale for crimes (wine taste) from paired comparison}
%  \end{figure} 
%}

%\subsection{Crowdsourcing Ranking on Internet}
%\frame{
%\frametitle{Crowdsourcing Ranking on Internet}
%
%  \begin{figure}[!h]
%\centering
%\includegraphics[width=0.8\textwidth]{figures/crowdsourcing_facemash.png} 
%\caption{Start from a movie -- \emph{The Social Network}}
%  \end{figure} 
%}

%\frame{
%  \frametitle{Netflix Customer-Product Rating}
%
%  \begin{example}[Netflix Customer-Product Rating]
%  \begin{itemize}
%  \item $480189$-by-$17770$ customer-product 5-star rating matrix $X$ with $X_{ij}=\{1,\ldots,5\}$
%  \item $X$ contains $98.82\%$ missing values
%  \end{itemize}
%  \end{example}
%
% However,
%
%\begin{itemize}
%\item pairwise comparison graph $G=(V,E)$ is very \textcolor{red}{dense}!
%
%\item only $0.22\%$ edges are missed, \textcolor{red}{almost a complete graph}
%
%\item rank aggregation may be carried out without estimating missing values
%
%\item \textcolor{red}{imbalanced}: number of raters on $e\in E$ varies
%\end{itemize}
%}
\frame{
	\frametitle{Paired comparison data on graphs}
	Graph $G=(V,E)$
	\begin{itemize} 
	\item $V$: alternatives to be ranked or rated 
	\item $(i_\alpha,j_\alpha) \in E$ a pair of alternatives 
	\item $y^\alpha_{ij}\in \R$ degree of preference by rater $\alpha$
	\item $\omega^\alpha_{ij}\in \R_+$ confidence weight of rater $\alpha$
	\item Examples: relative attributes, subjective QoE assessment, perception of illuminance intensity, sports, wine taste, etc. 
	\end{itemize}
	\begin{figure}[!h]
	\centering
	\includegraphics[width=0.3\textwidth]{figures/pagerank.png} \ \ 
	\includegraphics[width=0.3\textwidth]{figures/pairwise_rank_graph.png}
%	\caption{Crowdsouring subjective image quality evaluation}
	\end{figure} 
}

\frame{
\frametitle{Modern settings}
Modern ranking data are
\begin{itemize}
\item \textcolor{red}{distributive} on networks
\item \textcolor{red}{incomplete} with missing values
\item \textcolor{red}{imbalanced} 
\item even adaptive to \textcolor{red}{dynamic} and \textcolor{red}{random} settings?
\end{itemize}

Here we introduce: 

\begin{center}
\textcolor{blue}{Hodge Theory approach to Social Choice}
\end{center}
}

\subsection{Social Choice and Impossibility Theorems}

\frame{
\frametitle{History}

 Classical social choice theory origins from Voting Theory
\begin{itemize}
%\item \textcolor{red}{How to aggregate preferences which faithfully represent individuals?}
\item \emph{Borda} 1770, B. Count against plurality vote 
\item \emph{Condorcet} 1785, C. Winner who wins all paired elections 
\item Impossibility theorems: \emph{Kenneth Arrow} 1963, \emph{Amartya Sen} 1973
\item Resolving conflicts: \emph{Kemeny}, \emph{Saari} ...  
%\item Internet provides us a plethora of new examples
%\subitem Recommendation systems (Amazon, netflix, ...)
%\subitem Peer review systems (CiteSeer, Google's pagerank, eBay, ...)
%\subitem Crowdsourced ranking ({\tt{allourideas}, \tt{crowdrank}}, ...)
\item In these settings, we study \textcolor{red}{complete ranking orders} from voters.
\end{itemize}
}

\frame{
\frametitle{Classical Social Choice or Voting Theory}
  \begin{problem} 
  Given $m$ voters whose preferences are \textcolor{red}{total orders (permutation)} $\{\succeq_i: i=1,\dots,m\}$ on a candidate set $V$, 
  find a social choice mapping
\[f: (\succeq_1,\dots, \succeq_m) \mapsto \succeq^\ast, \]
as a total order on $V$, which ``best" represents voter's will.
\end{problem}
%\textcolor{red}{Arrow's impossibility theorem} says No to its existence ...
}


\frame{
\frametitle{Example: 3 candidates ABC}
 
% \begin{columns} 
%\begin{column}{0.6\textwidth} 
\begin{table}[htbp]
  \centering
  \begin{tabular}{@{} cc @{}}
    \hline\hline
    Preference order & Votes \\ 
    \hline
    $A\succeq B \succeq C$ & 2 \\ 
    $B \succeq A  \succeq C$ & 3 \\ 
    $B\succeq C\succeq A$ & 1 \\ 
    $C\succeq B\succeq A$ & 3 \\ 
    $C\succeq A\succeq B$ & 2 \\ 
    $A\succeq C\succeq B$ & 2 \\ 
    \hline
  \end{tabular}
%  \caption{TableCaption}
  \label{tab:label}
\end{table}
%\end{column} 
%\begin{column}{0.4\textwidth} 
%\begin{figure}[!h]
%\centering
%\includegraphics[width=\textwidth]{./figures/saari_triangle0.png} 
%%\caption{Courtesy by Asu Ozdaglar}
%  \end{figure} 
%\end{column} 
%\end{columns} 
}


\frame{
\frametitle{What we did in practice I: Position rules}
There are two important classes of social mapping in realities: 
\begin{itemize}
\item \textcolor{blue}{I. Position rules}: assign a \textcolor{red}{score} $s:V\to \R$, such that for each voter's order(permutation) $\sigma_i \in S_n$ ($i=1,\ldots,m$), $s_{\sigma_i(k)}\geq s_{\sigma_i(k+1)}$. Define the social order by the descending order of \textcolor{blue}{total score} over raters, i.e. the score for $k$-th candidate 
$$f(k)=\sum_{i=1}^m s_{\sigma_i}(k).$$
\subitem \textcolor{red}{Borda Count}: $s:V\to\R$ is given by $(n-1,n-2,\ldots,1,0)$
\subitem \textcolor{red}{Vote-for-top-1}: $(1,0,\ldots,0)$
\subitem \textcolor{red}{Vote-for-top-2}: $(1, 1, 0,\ldots,0)$
\end{itemize}
}

%\frame{
%\frametitle{Modern Examples: Mean Opinion Score}
%
%\begin{figure}[!h]
%\centering
%\includegraphics[width=0.6\textwidth]{figures/MOS_table.png} 
%%\caption{Start from a movie -- \emph{The Social Network}}
%  \end{figure} 
% widely used for evaluation of videos, as well books and movies, etc., but  
%  \medskip
%  \begin{itemize}
%  \item Ambiguity in definition of the \textcolor{red}{scale};
%  \item Difficult to verify whether a participant gives \textcolor{red}{false ratings}
%either intentionally or carelessly.
%  \end{itemize}
%}

\frame{
\frametitle{What we did in practice II: pairwise rules}
\begin{itemize}
\item \textcolor{blue}{II. Pairwise rules}: convert the voting profile, a (distribution) function on $n!$ set $S_n$, into \textcolor{red}{paired comparison matrix} $X\in \R^{n\times n}$ where $X(i,j)$ is the number (distribution) of voters that $i\succ j$; define the social order based on paired comparison data $X$.   
\subitem \textcolor{red}{Kemeny Optimization}: minimizes the number of pairwise mismatches to $X$ over $S_n$ (\textcolor{red}{NP}-hard)
\subitem \textcolor{red}{Pluarity}: the number of wins in paired comparisons (tournaments) -- equivalent to Borda count in complete Round-Robin tournaments 
\end{itemize}
}

\frame{
\frametitle{Revisit the ABC-Example}
 
 \begin{columns} 
\begin{column}{0.5\textwidth} 
\begin{itemize}
\item Position: 
\subitem $s<1/2$, $C$ wins
\subitem $s=1/2$, ties
\subitem $s>1/2$, $A/B$ wins 
\item Pairwise:
\subitem $A$, $B$: 13 wins 
\subitem $C$: 14 wins
\subitem Kemeny winner $C$
\end{itemize}
so completely in chaos!
\end{column} 
\begin{column}{0.5\textwidth} 
\begin{figure}[!h]
\centering
\includegraphics[width=\textwidth]{./figures/saari_triangle0.png} 
%\caption{Courtesy by Asu Ozdaglar}
  \end{figure} 
\end{column} 
\end{columns} 
}

\frame{
	\frametitle{Arrow's Impossibility Theorem}
	\begin{thm}[Arrow'1963] Consider the Unrestricted Domain, i.e. voters may have all complete and transitive preferences. 
	The only social choice rule satisfying the following conditions is the \textcolor{red}{dictator} rule 
	\begin{itemize}
	\item \textcolor{red}{Pareto (Unanimity)}: if all voters agree that $A\succeq B$ then such a preference should appear in the social order
	\item \textcolor{red}{Independence of Irrelevant Alternative (IIA)}: the social order of any pair only depends on voter's relative rankings of that pair 
	\end{itemize}
	\end{thm}
	}

\frame{
	\frametitle{Sen's Impossibility Theorem}
	\begin{thm}[Sen'1970] With Unrestricted Domain, there are cases with voting data that no social choice mapping,
	\[  f: (\succeq_1,\dots, \succeq_m) \mapsto 2^{V}, \]
	exists under the following conditions
	\begin{itemize}
	\item \textcolor{red}{Pareto}: if all voters agree that $A>B$ then such a preference should appear in the social order
	\item \textcolor{red}{Minimal Liberalism}: two distinct voters decide social orders of two distinct pairs respectively 
	\end{itemize}
	\end{thm}
	}


%\frame{
%\frametitle{Paired Comparisons vs. MOS}
%\begin{itemize}
%\item CiteSeer, PageRank, Amazon recommendation
%\item Individual decision process in paired comparison is simpler than in the typical MOS test, as the five-scale rating is reduced to a \textcolor{blue}{dichotomous} choice;
%\item But the paired comparison methodology leaves a \textcolor{red}{heavier
%burden} on participants with a larger number $n \choose 2$ of comparisons, compared with a linear score
%\end{itemize}
%}
%

\subsection[Saari Decomposition]{Saari Decomposition and Borda Count}
\frame{
\frametitle{A Decomposition of Voting Profile $R^{3!}$}
\begin{figure}[!h]
\centering
\includegraphics[width=\textwidth]{figures/saari_decomp3.png} 
%\caption{Courtesy by Asu Ozdaglar}
  \end{figure} 
}


\frame{
\frametitle{Saari Decomposition of Complete Voting Profile}
Every profile, or distribution function on symmetric group $S_n$, can be decomposed into the following components:
\begin{itemize}
\item \textcolor{red}{Universal kernel}: all ranking methods induce a complete tie on any subset of $V$
\subitem dimension: $n!-2^{n-1} (n-2)-2$
\item \textcolor{red}{Borda} profile: all ranking methods give the same result
\subitem dimension: $n-1$
\subitem basis: $\{ 1(\sigma(1)=i,*) -1(*,\sigma(n)=i): i=1,\ldots,n\}$
\item \textcolor{red}{Condorcet} profile: all positional rules give the same result
\subitem dimension: $\frac{(n-1)!}{2}$
\subitem basis: sum of $Z_n$ orbit of $\sigma$ minus their reversals
\item \textcolor{red}{Departure} profile: all pairwise rules give the same result
\end{itemize} 
}


\frame{
\frametitle{Borda Count: the most faithful representation?}
Borda count is the most consistent ranking method, since
\begin{itemize}
\item for \textcolor{blue}{full set} ranking, it only depends on \textcolor{red}{Borda} profile
\item for \textcolor{blue}{subset} ranking it depends on both \textcolor{red}{Borda} and \textcolor{red}{Condorcet} profiles
\end{itemize}
while
\begin{itemize}
\item \textcolor{blue}{Pairwise} rules depend on both \textcolor{red}{Borda} and \textcolor{red}{Condorcet} profiles 
\item \textcolor{blue}{Position} rules depend on both \textcolor{red}{Borda} and \textcolor{red}{Departure} profiles (except Borda)
\end{itemize}
So, if you look for best \textcolor{red}{possibility} from \textcolor{blue}{impossibility}, perhaps Borda count is the choice. 
}


\frame{
 \frametitle{Borda Count as a Pairwise Rule: Least Square}
Borda Count is equivalent to 
\[
\min_{x \in {\mathrm R}^{|V|}}  \sum_{\alpha, \{i,j\}\in E} (x_i - x_j - y^\alpha_{ij})^2,
\]
where 
 \begin{itemize}
 \item $y_{ij}^\alpha>0$ (e.g. 1), if $i\succeq j$ by voter $\alpha$, and $y_{ij}^\alpha<0$, on the opposite (e.g. -1).
 \end{itemize} 
 Note: \textcolor{red}{NP-hard} \textcolor{blue}{Kemeny Optimization, or Minimimum-Feedback-Arc-Set}:
 \[ \min_{x\in {\mathrm R}^{|V|}}  \sum_{\alpha,\{i,j\}\in E}  (\textcolor{red}{\sign}(x_i - x_j) - y^\alpha_{ij})^2, \]
}

\subsection[Hodge Decomposition of Pairwise Ranking]{HodgeRank: generalized Borda Count}
\frame{
	\frametitle{Generalized Borda Count with Incomplete Data}
 \[ \min_{x\in {\mathrm R}^{|V|}}  \sum_{\alpha, \{i,j\}\in E} \omega_{ij}^\alpha (x_i - x_j -y^\alpha_{ij})^2, \]
 \[ \Leftrightarrow \]
 \[ \textcolor{blue}{\min_{x\in {\mathrm R}^{|V|}}  \omega_{ij} \sum_{\{i,j\}\in E}  ((x_i - x_j) -\hat{y}_{ij})^2}, \]
 \[\mbox{where } \hat{y}_{ij}=\hat{\E}_\alpha y^\alpha_{ij}=( \sum_\alpha \omega_{ij}^\alpha y^\alpha_{ij}) /\omega_{ij} = -\hat{y}_{ji}, \ \ \ \omega_{ij}=\sum_\alpha \omega_{ij}^\alpha\]
 So $\hat{y}\in \textcolor{blue}{l^2_\omega(E)}$, inner product space with $\langle u,v\rangle_\omega = \sum u_{ij} v_{ij} \omega_{ij}$, $u,v$ skew-symmetric
	}
	
\frame{
 \frametitle{Statistical Majority Voting: $l^2(E)$}
 \begin{itemize}
% \item Majority voting (Condorcet'1785): inconsistency arises (\textcolor{red}{Arrow's impossibility theorem} 1950s)
% \item Statistical majority voting:
 \item $\hat{y}_{ij}=( \sum_\alpha \omega_{ij}^\alpha y^\alpha_{ij}) / (\sum_\alpha \omega_{ij}^\alpha )=-\hat{y}_{ji}$, $\omega_{ij} = \sum_\alpha \omega^\alpha_{ij}$
 \item $\hat{y}$ from generalized linear models: 
\subitem[1] \emph{Uniform} model: $\hat{y}_{ij}=2\hat{\pi}_{ij}-1.$ 
\subitem[2] \emph{Bradley-Terry} model: $\hat{y}_{ij}={\mathrm{log}}\frac{\hat{\pi}_{ij} } {1-\hat{\pi}_{ij}}. $
\subitem[3] \emph{Thurstone-Mosteller} model: $\hat{y}_{ij}=\Phi^{-1}(\hat{\pi}_{ij}),$ $\Phi(x)$ is Gaussian CDF 
%\[
%\Phi(x)= \frac{1}{\sqrt{2\pi}} \int_{-x/[2\sigma^2 (1-\rho)]^{1/2}}^\infty e^{-\frac{1}{2} t^2 } d t .
%\]
\subitem[4] \emph{Angular transform} model: $\hat{y}_{ij}=\arcsin(2\hat{\pi}_{ij}-1)$.
 \end{itemize} 
}

\frame{
\frametitle{Hodge Decomposition of Pairwise Ranking}
% \begin{figure}[!h]
%\centering
%\includegraphics[width=0.4\textwidth]{figures/HodgeRank.png} 
%%\caption{Start from a movie -- \emph{The Social Network}}
%  \end{figure} 
\begin{thm}
$\hat{y}_{ij}=-\hat{y}_{ji}\in l^2_\omega(E)$ admits an \textcolor{red}{orthogonal} decomposition, 
 \begin{equation}
\textcolor{red}{\hat{y} = A x + B^T z + w},
\end{equation}
where
\begin{subequations}
\begin{align}
(A x)(i,j) := x_i - x_j, & \ \ \textrm{gradient, as \textcolor{blue}{Borda} profile}, \\
(B \hat{y})(i,j,k):=\hat{y}_{ij} + \hat{y}_{jk} + \hat{y}_{ki}, & \ \ \textrm{trianglar cycle/curl, \textcolor{blue}{Condorcet}}\\
w\in \ker(A^T) \cap \ker(B), & \ \ \textrm{harmonic, \textcolor{blue}{Condorcet}} .
\end{align}
\end{subequations}
In other words
\[ \textcolor{red}{\im(A) \oplus \ker(A A^T+B^T B) \oplus \im(B^T) }\]
\end{thm}
}

\frame{
\frametitle{Why?}
% \begin{figure}[!h]
%\centering
%\includegraphics[width=0.4\textwidth]{figures/HodgeRank.png} 
%%\caption{Start from a movie -- \emph{The Social Network}}
%  \end{figure} 
Note \textcolor{red}{$B\circ A =0$} since 
\[ (B\circ A x)(i,j,k) = (x_i - x_j) + (x_j - x_k) + (x_k - x_i ) =0. \]
Hence
\[ A^T \hat{y} = A^T (A x + B^T z + w) =  A^TA x \Rightarrow x =(A^TA)^\dagger A^T \hat{y} \]
\[ B\hat{y} =B (A x + B^T z + w) = B B^T z \Rightarrow z=(B B^T)^\dagger B \hat{y} \]
\[ A^T w = B w =0 \Rightarrow w\in \ker (\Delta_1), \ \ \Delta_1=A A^T + B^T B. \]
}

%\frame{
%\frametitle{In other words [Jiang-Lim-Y.-Ye'11]}
%% \begin{figure}[!h]
%%\centering
%%\includegraphics[width=0.4\textwidth]{figures/HodgeRank.png} 
%%%\caption{Start from a movie -- \emph{The Social Network}}
%%  \end{figure} 
%\begin{thm}
%$\hat{y}_{ij}=-\hat{y}_{ji}\in l^2_\omega(E)$ admits an \textcolor{red}{orthogonal} decomposition, 
% \begin{equation}
%\textcolor{red}{\hat{y} = \hat{y}^{(g)} + \hat{y}^{(h)} + \hat{y}^{(c)}},
%\end{equation}
%where
%\begin{subequations}
%\begin{align}
%\hat{y}^{(g)}_{ij}  = x_i - x_j, & \ \ \textrm{for some}\ x\in {\mathrm R}^{V} , \\
%\hat{y}^{(h)}_{ij} + \hat{y}^{(h)}_{jk} + \hat{y}^{(h)}_{ki} = 0, & \ \ \textrm{for each $\{i,j,k\}\in T$} , \label{eq:curl-free} \\
%\sum_{j\sim i} \omega_{ij}\hat{y}^{(h)}_{ij} = 0, & \ \ \textrm{for each $i\in V$} \label{eq:divergence-free}.
%\end{align}
%\end{subequations}
%\end{thm}
%}
%
\frame{
\frametitle{Generalized Borda Count estimator}
 Gradient flow $\hat{y}^{(g)}:=(A x)(i,j) = x_i - x_j$ gives the generalized Borda count score, $x$ which solves \textcolor{red}{Graph Laplacian equation}
 \begin{equation*}
\min_{x \in {\R}^{|V|}} \sum_{\alpha, (i,j)\in E}\omega_{ij}^\alpha (x_i - x_j - y_{ij}^\alpha)^2 \Leftrightarrow \Delta_0 x = A^T \hat{y} 
\end{equation*}
where $\Delta_0= A^T A$ is the unnormalized graph Laplacian of $G$. 
\begin{itemize}
\item In theory, \textcolor{red}{nearly linear algorithms} for such equations, e.g. \textcolor{blue}{Spielman-Teng'04, Koutis-Miller-Peng'12}, etc. 
\item But in practice? ...
\end{itemize}
%But no one has implemented such algorithms yet!
%Residues $\hat{Y}^{(h)}$ and $\hat{Y}^{(c)}$ accounts for \textcolor{red}{inconsistencies}:
% \begin{itemize}
%\item $\hat{Y}^{(c)}$, the \textcolor{red}{local} inconsistency, triangular curls
%\subitem $\hat{Y}^{(c)}_{ij} + \hat{Y}^{(c)}_{jk} + \hat{Y}^{(c)}_{ki} \neq 0 $ , $\{i,j,k\}\in T$
%\item $\hat{Y}^{(h)}$, the \textcolor{red}{global} inconsistency, harmonic ranking
%\subitem harmonic ranking leads to \emph{circular coordinates} on $V$ $\Rightarrow$ \emph{fixed tournament} issue
%\subitem it creates all \emph{chaotic} voting results
%\end{itemize}
}

\frame{
\frametitle{Online HodgeRank as Stochastic Approximations}
\textcolor{blue}{Robbins-Monro} (1951) algorithm for $\bar{A}x=\bar{b}$
\[ x_{t+1} = x_t - \gamma_t (A_t x_t - b_t), \ \ \ \E(A_t) =\bar{A}, \ \E(b_t) =b \]
Now consider $\Delta_0 x =  \delta_0^\ast \hat{y}$, with new rating $y_t(i_{t+1},j_{t+1})$
\begin{eqnarray*}
x_{t+1}(i_{t+1}) & = & x_{t}(i_{t+1}) - \gamma_t [x_t(i_{t+1}) - x_t(j_{t+1}) - y_t(i_{t+1},j_{t+1})] \\
x_{t+1}(j_{t+1}) & = & x_{t}(j_{t+1}) + \gamma_t [x_t(i_{t+1}) - x_t(j_{t+1}) - y_t(i_{t+1},j_{t+1})] 
\end{eqnarray*}
Note: 
\begin{itemize}
\item updates only occur locally on edge $\{i_{t+1},j_{t+1}\}$
\item initial choice: $s_{0}=0$ or any vector $\sum_i x_0 (i)=0$
\item step size 
\subitem $\gamma_t = a (t+b)^{-\theta}$ ($\theta\in (0,1]$) 
\subitem $\gamma_t = const(T)$, .e.g. $1/T$ where $T$ is total sample size
\end{itemize}
}

\frame{
\frametitle{Minimax Optimal Convergence Rates}
\begin{itemize}
\item Choose $\gamma_t\sim t^{-1/2}$ (e.g. a=$1/\lambda_1(\Delta_0)$ and $b$ large enough)
\item In this case, $s_t$ converges to $s^\ast$ (population solution) in the (optimal) rate of $t$ 
\[ \E \|x_t - x^\ast\|^2\leq O\left(\textcolor{red}{t^{-1} \cdot \lambda_2^{-2}(\Delta_0) } \right) \]
where $\lambda_2(\Delta_0)$ is the Fiedler Value of graph Laplacian
\item Using Tong Zhang's stochastic variance reduction gradient (SVRG)
\[ \E \|x_t - x^\ast\|^2\leq O\left(\textcolor{red}{t^{-1} + \lambda_2^{-2}(\Delta_0) t^{-2}}\right) \]
%\item Dependence on $\lambda_1^{-3/2}$ can be improved to $\lambda_1^{-1}$ by Ji Liu (U Wisc-Madison) (\textcolor{red}{optimal order of $\kappa$?})
\end{itemize}
%\begin{figure}[!h]
%\centering
%\includegraphics[width=0.4\textwidth]{figures/onlinerates.png} 
%%\caption{Start from a movie -- \emph{The Social Network}}
%  \end{figure} 
%
}


\frame{
\frametitle{Condorcet Profile splits into Local vs. Global Cycles}
%Residues $\hat{Y}^{(2)}$ and $\hat{Y}^{(3)}$ accounts for \textcolor{red}{inconsistencies}, locally or globally, to characterize \textcolor{blue}{reliability or intrinsic conflicts of data}
% \begin{itemize}
%\item $\hat{Y}^{(3)}$, the \textcolor{red}{local} inconsistency, triangular curls
%\subitem $\hat{Y}^{(3)}_{ij} + \hat{Y}^{(3)}_{jk} + \hat{Y}^{(3)}_{ki} \neq 0 $ , $\{i,j,k\}\in T$
%\item $\hat{Y}^{(2)}$, the \textcolor{red}{global} inconsistency, harmonic ranking
%\subitem $\hat{Y}^{(2)}$ vanishes if \textcolor{red}{1-homology} of $\chi_G$ vanishes
%\subitem harmonic ranking is a \textcolor{red}{circular coordinate} and generally non-sparse $\Rightarrow$ \textcolor{red}{fixed tournament} issue
%\end{itemize}
Residues $\hat{y}^{(c)}=B^T z$ and $\hat{y}^{(h)}=w$ are cyclic rankings, accounting for conflicts of interests:
 \begin{itemize}
\item $\hat{y}^{(c)}$, the \textcolor{red}{local/triangular} inconsistency, triangular curls  (\textcolor{blue}{$Z_3$-invariant})
\subitem $\hat{y}^{(c)}_{ij} + \hat{y}^{(c)}_{jk} + \hat{y}^{(c)}_{ki} \neq 0 $ , $\{i,j,k\}\in T$
%\item $\hat{y}^{(h)}$, the \textcolor{red}{global} inconsistency, harmonic ranking (\textcolor{blue}{$Z_n$-invariant})
%\begin{subequations}
%\begin{align}
%\hat{y}^{(h)}_{ij} + \hat{y}^{(h)}_{jk} + \hat{y}^{(h)}_{ki} = 0, & \ \ \textrm{for each $\{i,j,k\}\in T$} , \label{eq:curl-free} \\
%\sum_{j\sim i} \omega_{ij}\hat{y}^{(h)}_{ij} = 0, & \ \ \textrm{for each $i\in V$} \label{eq:divergence-free}.
%\end{align}
%\end{subequations}
%\subitem \textcolor{red}{voting chaos}: \emph{circular coordinates} on $V$ $\Rightarrow$ \emph{fixed tournament} issue
%%\subitem it creates all \emph{chaotic} voting results
\end{itemize}
\begin{figure}[!h]
\centering
\includegraphics[width=0.45\textwidth]{figures/Tennis-cycle.pdf} 
%\includegraphics[width=0.3\textwidth]{figures/Harmonic-cycle.pdf} 
%\caption{Courtesy by Asu Ozdaglar}
 \end{figure} 
}

\frame{
\frametitle{Condorcet Profile in Harmonic Ranking}
\begin{itemize}
\item $\hat{y}^{(h)}=w$, the \textcolor{red}{global} inconsistency, harmonic ranking (\textcolor{blue}{$Z_n$-invariant})
\begin{subequations}
\begin{align}
\hat{y}^{(h)}_{ij} + \hat{y}^{(h)}_{jk} + \hat{y}^{(h)}_{ki} = 0, & \ \ \textrm{for each $\{i,j,k\}\in T$} , \label{eq:curl-free} \\
\sum_{j\sim i} \omega_{ij}\hat{y}^{(h)}_{ij} = 0, & \ \ \textrm{for each $i\in V$} \label{eq:divergence-free}.
\end{align}
\end{subequations}
\subitem \textcolor{red}{voting chaos}: \emph{circular coordinates} on $V$ $\Rightarrow$ \emph{fixed tournament} issue
%\subitem it creates all \emph{chaotic} voting results
\end{itemize}
\begin{figure}[!h]
\centering
%\includegraphics[width=0.45\textwidth]{figures/Tennis-cycle.pdf} 
\includegraphics[width=0.3\textwidth]{figures/Harmonic-cycle.pdf} 
%\caption{Courtesy by Asu Ozdaglar}
 \end{figure} 
}

\subsection{Cyclicity, Topology, and Random Graph Models}

\frame{
	\frametitle{Cyclic Ranking and Outliers [Xu-Xiong-Huang-Y.'13]}
	\begin{itemize}
	\item Robust ranking can be formulated as a Huber's LASSO problem (Gannaz'07, She-Owen'09, Fan-Tang-Shi'12)
	\item Sparse outliers are sparse approximation of cyclic rankings (curl+harmonic)
	\item Bregman ISS or linearized Bregman iterations: efficient algorithms
	\item Exact recovery is possible without Gaussian noise
	\item Outlier detection is possible against Gaussian noise, provided
	\subitem Irrepresentable condition (e.g. random graph)
	\subitem Outliers have large enough magnitudes
	\end{itemize}	
	}

\frame{
\frametitle{Topological Obstructions}
Two \textcolor{red}{topological} conditions are important:
\begin{itemize}
\item \textcolor{red}{Connectivity}: 
\subitem $G$ is connected $\Rightarrow$ unique global ranking is possible;
\item \textcolor{red}{Loop-free}: 
\subitem for cyclic rankings, consider clique complex $\chi^2_G=(V,E,T)$ by attaching triangles $T=\{(i,j,k)\}$
\subitem $\dim(\ker(\Delta_1)) = \beta_1(\chi^2_G)$, so harmonic ranking $w=0$ if $\chi^2_G$ is loop-free, 
here topology plays a role of \textcolor{red}{obstruction of fixed-tournament}
\subitem ``\textcolor{blue}{Triangular arbitrage-free implies arbitrage-free}"
\end{itemize}
 \begin{figure}[!h]
\includegraphics[width=0.1\textwidth]{figures/??.png} 
%\caption{Start from a movie -- \emph{The Social Network}}
  \end{figure} 
}


%\frame{
%\frametitle{Persistent Homology: online algorithm for topology tracking (e.g Edelsbrunner-Harer'08)}
% 
% \begin{columns} 
%\begin{column}{0.6\textwidth} 
%\begin{figure}[h]
%\centering
%	\includegraphics[width=0.7\textwidth]{figures/persistent.png} 
%	\caption{Persistent Homology Barcodes} 
%\end{figure}
%\end{column} 
%
%\begin{column}{0.4\textwidth} 
%\begin{itemize}
%\item vertice, edges, and triangles etc. sequentially added  
%\item online update of homology
%\item $O(m)$ for surface embeddable complex; and $O(m^{2.xx})$  in general ($m$ number of simplex)
%\end{itemize}
%\end{column} 
%\end{columns} 
%}
%



%\frame{
%	  \frametitle{Combinatorial Laplacian}	  
%	  \begin{itemize}
%	  \item Define the $k$-dimensional \textcolor{red}{combinatorial Laplacian}, $\Delta_k:\Omega^k \to \Omega^k$ by
%	\[ \Delta_k = d_{k-1} d_{k-1}^\ast + d_k^\ast d_k, \qquad k>0 \]   
%	  \item $k=0$, $\Delta_0 = d_0^\ast d_0$ is the well-known \textcolor{red}{graph Laplacian}
%	  \item $k=1$, 1-Hodge Laplacian
%	\[ \textcolor{red}{\Delta_1 = \curl \circ \curl^\ast - \dive \circ \grad} \]
%	  \item Important Properties: 
%	  \subitem $\Delta_k$ positive semi-definite
%	  \subitem $\ker(\Delta_k)=\ker(d_{k-1}^\ast)\cap\ker(d_k)$: $k$-\textcolor{red}{Harmonics}, dimension equals to $k$-th Betti number of $\chi_G^3$
%	\end{itemize}
%}


%\frame{
%\frametitle{Combinatorial Hodge Theory on Triangulated Graphs}
%\begin{itemize}
%\item Graph $G=(V,E)\mapsto\chi_G^{3}=(V,E,T)$, triangular clique complex
%\item Every edge flow $\in l^2(E)$ admits the orthogonal decomposition
%	\[
%	\text{gradient flow} + \text{globally cyclic} + \text{locally (triangularly) cyclic}	\]
%%\item Matrix: every skew-symmetric matrix $X=-X^T$ \textcolor{red}{with missing values} can be decomposed into 
%%\[ X = X^{(1)} + X^{(2)} + X^{(3)} \]
%%where $X^{(1)}_{ij}=\beta_i - \beta_j$ a gradient flow, $X^{(2)}$ and $X^{(3)}$ are cyclic flows ($\sum_{j\sim i} X^{(*)}_{ij}=0$, harmonic and curl). 
%%%\item There are more, e.g. Hodge Theory on Sheafs (Joe Friedman). 
%\end{itemize}
%\begin{figure}[!h]
%\centering
%\includegraphics[width=0.3\textwidth]{figures/Ozdaglar.png} 
%\caption{Courtesy by Asu Ozdaglar}
%  \end{figure} 
%}
%


%\frame{
%	\frametitle{Summary}%
%	Discrete de Rham complex: 
%	\[
%	\Omega^{0} \xrightarrow{d_0} \Omega^{1}\xrightarrow{d_1} \Omega^{2},
%	\]
%	i.e.
%	\[
%	\text{Potential}\xrightarrow{\operatorname*{grad}}\text{Edge-flow}%
%	\xrightarrow{\operatorname*{curl}}\text{Triangular-curl}%
%	\]
%	\[
%	\text{Potential}%
%	\xleftarrow{\operatorname*{grad}^\ast (=:-\operatorname*{div})}\text{Edge-flow}%
%	\xleftarrow{\operatorname*{curl}^\ast}\text{Triangular-curl}.
%	\]
%	Note that
%	\[
%	\operatorname*{curl}\circ\operatorname*{grad}(\text{Potential})=0 \Leftrightarrow d_1 d_0 =0.
%	\]
%	Hodge decomposition
%	\[ \text{Edge-flow}= \operatorname*{grad}(\text{Potential})\oplus \text{harmonic}\oplus {\curl}^\ast(\text{Triangular}) \]
%	}

%\frame{
%	\frametitle{Combinatorial Hodge theory: matrix version}%
%
%	A skew-symmetric matrix $W$ associated with $G$ (\textcolor{red}{with missing values}) can be decomposed uniquely
%	\[
%	W = W_{1} + W_{2} + W_{3}
%	\]
%	where
%	\tiny{
%	\begin{itemize}
%	\item $W_{1}$ satisfies
%		\subitem `\textit{integrable}': $W_{1}(i,j)=v_{j}-v_{i}$ for some $v:V\rightarrow
%	\mathbb{R}$.
%	\item $W_{2}$ satisfies
%		\subitem `\textit{curl free}': $W_{2}(i,j)+W_{2}(j,k)+W_{2}(k,i)=0$ for all $3$-clique
%	$(i,j,k)$;
%		\subitem `\textit{divergence free}': $\sum_{j:(i,j)\in E}W_{2}(i,j)=0$
%	\item $W_{3}\perp W_{1}$ and $W_{3}\perp W_{2}$, which is divergence-free but not curl-free
%	\end{itemize}
%	}
%}
%

%\frame{
%	\frametitle{Forgetful functors}
%	\[ \text{Riemannian manifolds} \to \text{Metric spaces} \to \text{Cell complexes} \]
%	\begin{itemize}
%	\item From differentiable to combinatorial structures, Hodge decomposition is functorial (invariant)
%	\item Topological invariants (homology) are preserved in such coarse-grained functors
%	\item Natural for data analysis, a connection between geometry and topology: harmonic basis
%	\item More important than data itself, \textcolor{blue}{relations} between data via functions, mappings, etc.
%	\end{itemize}
%	}
%%
%\frame{
%	  \frametitle{Clique Complex of a Graph}
%	Extend graph $G=(V,E)$ to a \textcolor{red}{simplicial complex} $\chi(G)$ by
%	attaching triangles
%	  \begin{itemize}
%	  \item 0-simplices $\chi_0(G)$: $V$
%	  \item 1-simplices $\chi_1(G)$: $E$
%	  \item 2-simplices $\chi_2(G)$: 3-cliques $\{i,j,k\}$ such that every edge exists in $E$
%	  \item $k$-simplices $\chi_{k}(G)$: $(k+1)$-cliques $\{i_{0},\dots
%	,i_{k}\}$ of $G$
%	  \end{itemize}
%	  \textcolor{blue}{Note}: it suffices here to construct $\chi(G)$ up to dimension \textcolor{red}{2}!
%}





%\section[Applications]{Applications of Hodge Decomposition}
%
%\frame{
%	\frametitle{Applications of Hodge Decomposition}
%	\begin{itemize}
%	\item Boundary Value Problem (Schwarz, Chorin-Marsden'92)
%	\item Computer vision
%	\subitem Optical flow decomposition and regularization (Yuan-Schn\"{o}rr-Steidl'2008, etc.)
%	\subitem Retinex theory and shade-removal (Ma-Morel-Osher-Chien'2011)
%	\subitem Relative attributes (Fu-Xiang-Y. et al. 2014)
%	\item Sensor Network coverage (Jadbabai et al.'10)
%	\item Statistical Ranking or Preference Aggregation (Jiang-Lim-Y.-Ye'2011, etc.)
%	\item Decomposition of Finite Games (Candogan-Menache-Ozdaglar-Parrilo'2011)
%	\end{itemize}
%}
%

%\subsection{Computer Vision}
%
%\frame{
%\frametitle{Optical Flow Decomposition and Regularization}
%\begin{itemize}
%\item Rudin-Osher-Fatemi'1992: piecewise \textcolor{red}{constant} flows
%\[ \frac{1}{2}\|v - u\|_2^2 + TV(u), \ \ u,v\in \R^2 \]
%\[ TV(u):=\int \sqrt{(\grad u_1)^2 + (\grad u_2)^2},  \]
%\item Yuan-Schn\"{o}rr-Steidl'2007: piecewise \textcolor{red}{harmonic} flows
%\[ TV(u)\to R(u) = \int \sqrt{(\dive u)^2 + (\curl u)^2} \]
%\end{itemize}
%}
%
%\frame{
%\frametitle{Example: periodic motions are harmonic}
%	\begin{figure}[!t]
%	\includegraphics[width=0.45\textwidth]{./figure/flow0.png}
%	\includegraphics[width=0.5\textwidth]{./figure/TV-H.png} \\
%	\caption{Harmonic flows are adaptive to object rotation in receptive fields}
%	\end{figure}
%}
%
%
%\frame{
%\frametitle{Adelson's iIlusion in Computer Vision}
%	\begin{figure}[!t]
%	\includegraphics[width=0.4\textwidth]{./figures/checkershadow_illusion4med.jpg}
%	\includegraphics[width=0.4\textwidth]{./figures/checkershadow_proof4med.jpg} \\
%	\caption{Adelson's illusion: on the left the chess board is shadowed by a column such that the white square has the same illuminance intensity as the black square, proved by the right picture.  } \label{fig:illustration}
%  	\end{figure}
%}
%
%
%\frame{
%\frametitle{Retinex Theorey based on Approximation of Gradient Flows}
%
%  \begin{itemize}
%  \item The edge information is a gradient field of intensity $\grad I$
%  \item Shade adds \textcolor{red}{sparse} noise $Y = \grad I + E$
%  \item Sparse approximation of de-noised gradient field $\textcolor{red}{\min_X \|\grad X - T(Y)\|_1}$  
%  \end{itemize}
% \begin{figure}[!h]
%\centering
%\includegraphics[width=0.3\textwidth]{figures/Osher_Retina.png} 
%\caption{Ma-Morel-Osher-Chien 2011}
%  \end{figure}  
%}

%\subsection{Statistical Ranking via Paired Comparison Method} 
% \subsection{Examples}


%\subsection{Ranking in Economics}


%\frame{
%\frametitle{Implicit Feedback from Web Clicks}
%  \begin{figure}[!h]
%\centering
%\includegraphics[width=0.8\textwidth]{figures/click.png} 
%\caption{Clicks implies preference}
%  \end{figure} 
%}


%\frame{
%\frametitle{Mean Opinion Score in Ranking}
%
%\begin{figure}[!h]
%\centering
%\includegraphics[width=0.6\textwidth]{figures/MOS_table.png} 
%%caption{Start from a movie -- \emph{The Social Network}}
%  \end{figure} 
% widely used for evaluation of videos, as well books and movies, etc., but  
%  \medskip
%  \begin{itemize}
%  \item Ambiguity in definition of the \textcolor{red}{scale};
%  \item Difficult to verify whether a participant gives \textcolor{red}{false ratings}
%either intentionally or carelessly.
%  \end{itemize}
%}
%
%
%\frame{
%\frametitle{Netflix example revisited}
%
%	  \begin{columns}
%	  \small \begin{column}{0.47\textwidth}
%	  The \textbf{first order} statistics, mean score for each product, is often
%inadequate:
%	  \begin{itemize}
%	  \item most customers would rate just a \textcolor{blue}{very small portion} of the products
%	  \item different products might have different raters, whence mean scores
%involve noise due to \textcolor{blue}{arbitrary individual rating scales} (right figure)	  
%	  \end{itemize}
%	  \textcolor{red}{How about high order statistics}?
%	  \end{column}
%	  \begin{column}{0.53\textwidth}
%	  \begin{figure}
%	\includegraphics[width=0.8\textwidth]{figures/nflix_shakespeare.jpg} \\
%	\ \ \includegraphics[width=0.75\textwidth]{figures/nflix_dune.jpg}
%	  \end{figure}
%	  \end{column}
%	  \end{columns}
%}

%\frame{
%\frametitle{Paired Comparisons}
%\begin{itemize}
%\item Individual decision process in paired comparison is simpler than in the typical MOS test, as the five-scale rating is reduced to a \textcolor{blue}{dichotomous} choice;
%\item But the paired comparison methodology leaves a \textcolor{red}{heavier
%burden} on participants with a larger number $n \choose 2$ of comparisons
%\item Moreover, raters and item pairs enter the system in a \textcolor{red}{dynamic} and \textcolor{red}{random} way;
%\end{itemize}
%
%Here we propose: 
%
%\begin{center}
%\textcolor{blue}{Hodge Theoretic Approach \\ for Pairwise Ranking on Random Graphs}
%\end{center}
%}

%\frame{
%\frametitle{Most Relevant Topics in ICCHA 2011}
%\begin{itemize}
%\item Vin de Silva, Circular coordinates from Harmonic forms (Wednesday)
%\item Nat Smale, Hodge theory on metric spaces (\textcolor{red}{11:10-11:50am today, LT-1!})
%\end{itemize}
%}
%

%\subsubsection{HodgeRank on Graphs}


%\frame{
% \frametitle{Equivalently, in weighted Least Square}
%\[
%\min_{s\in {\mathrm R}^{|V|}}  \sum_{\{i,j\}\in E} \omega_{ij} (s_i - s_j -
%\hat{Y}_{ij})^2,
%\]
%where 
% \begin{itemize}
% \item $\hat{Y}_{ij}=( \sum_\alpha \omega_{ij}^\alpha Y^\alpha_{ij}) / (\sum_\alpha \omega_{ij}^\alpha )$, skew-symmetric matrix
% \item $\omega_{ij} = \sum_\alpha \omega^\alpha_{ij}$
% \item Inner product induced on $R^{E}$, $\langle u,v\rangle_\omega = \sum u_{ij} v_{ij} \omega_{ij}$ where $u,v$ skew-symmetric
% \end{itemize} 
% Note: \textcolor{red}{NP-hard} \textcolor{blue}{Kemeny Optimization, or Minimimum-Feedback-Arc-Set}:
% \[ \min_{s\in {\mathrm R}^{|V|}}  \sum_{\alpha,\{i,j\}\in E} \omega_{ij}^\alpha (\textcolor{red}{\sign}(s_i - s_j) -
%\hat{Y}^\alpha_{ij})^2, \]
%}

%\frame{
%\frametitle{Statistical General Linear Models for Binary Choices}
%Let $\pi_{ij}$ be the probability that $i$ is preferred to $j$. The family of \textcolor{red}{linear models} assumes that
%\[ \pi_{ij} = \Phi(s_i - s_j) \]
%for some symmetric cumulated distributed function $\Phi$. Reversely, given an observation $\hat{\pi}$, define
%\[ \hat{Y}_{ij} = \Phi^{-1}(\hat{\pi}_{ij}) \]
%One would like $\hat{Y}_{ij} \approx \hat{s}_i - \hat{s}_j$ for some $\hat{s}: V\to \R$ (in least squares, e.g.).
%}
%
%\frame{
%\frametitle{Examples of General Linear Models}
%1. \emph{Uniform} model:
%\begin{align}
%\hat{Y}_{ij}=2\hat{\pi}_{ij}-1.
%\end{align}
%
%2. \emph{Bradley-Terry} model:
%\begin{align}
%\hat{Y}_{ij}={\mathrm{log}}\frac{\hat{\pi}_{ij} } {1-\hat{\pi}_{ij}}.
%\end{align}
%
%3. \emph{Thurstone-Mosteller} model:
%\begin{align}
%\hat{Y}_{ij}=\Phi^{-1}(\hat{\pi}_{ij}).
%\end{align}
%%where $F$ is essentially the Gauss error function
%\[
%\Phi(x)= \frac{1}{\sqrt{2\pi}} \int_{-x/[2\sigma^2 (1-\rho)]^{1/2}}^\infty e^{-\frac{1}{2} t^2 } d t .
%\]
%
%4. \emph{Angular transform} model:
%\begin{align}
%\hat{Y}_{ij}=\arcsin(2\hat{\pi}_{ij}-1).
%\end{align}
%}
%
%\frame{
%\frametitle{Hodge Decomposition on Graphs [Jiang-Lim-Y.-Ye'11]}
% \begin{figure}[!h]
%\centering
%\includegraphics[width=0.4\textwidth]{figures/HodgeRank.png} 
%%\caption{Start from a movie -- \emph{The Social Network}}
%  \end{figure} 
% Paired comparison data $\hat{Y}_{ij}\in l^2_\omega(E)$ admits an \textcolor{red}{orthogonal} decomposition, 
% \begin{equation}
%\textcolor{red}{\hat{Y} = \hat{Y}^{(g)} + \hat{Y}^{(h)} + \hat{Y}^{(c)}},
%\end{equation}
%where
%\begin{equation}
%\hat{Y}^{(g)}_{ij}  = \hat{\beta}_i - \hat{\beta}_j,\ \ \textrm{for some}\ \hat{\theta}\in {\mathrm R}^{V} ,
%\end{equation}
%\begin{equation} \label{eq:curl-free}
%\hat{Y}^{(h)}_{ij} + \hat{Y}^{(h)}_{jk} + \hat{Y}^{(h)}_{ki} = 0, \ \textrm{for each $\{i,j,k\}\in T$} ,
%\end{equation}
%\begin{equation} \label{eq:divergence-free}
%\sum_{j\sim i} \omega_{ij}\hat{Y}^{(h)}_{ij} = 0, \ \textrm{for each $i\in V$} .
%\end{equation}
%}


%\section{Online HodgeRank}
%\subsection{Hodge Decomposition of Paired Ranking}
%\frame{
%\frametitle{Minimax Optimal Convergence Rates}
%\begin{itemize}
%\item Choose $\gamma_t\sim t^{-1/2}$ (e.g. a=$1/\lambda_1(\Delta_0)$ and $b$ large enough)
%\item In this case, $s_t$ converges to $s^\ast$ (population solution), with probability $1-\delta$, in the (optimal) rate of $t$
%\[ \|s_t - s^\ast\|\leq O\left(\textcolor{red}{t^{-1/2} \cdot \lambda_2^{-3/2}(\Delta_0) }\cdot \log^{1/2} \frac{1}{\delta} \right) \]
%where $\lambda_2(\Delta_0)$ is the Fiedler Value of graph Laplacian
%% \item The same asymptotic rates as batch algorithm
%%\item Dependence on $\lambda_1^{-3/2}$ can be improved to $\lambda_1^{-1}$ by Ji Liu (U Wisc-Madison) (\textcolor{red}{optimal order of $\kappa$?})
%\end{itemize}
%\textcolor{red}{Open}: Almost sure convergence is normally achieved by Martingale-convergence Thm, with additional mean square error rate $\E\|s_t -s^\ast\|^2 \leq O(t^{-1} \cdot \lambda_2^{-2}(\Delta_0))$, in what sense it is \textcolor{blue}{optimal in both $t$ and $\lambda_2$}? Can we reach both a.s. and error rates using \textcolor{blue}{Bernstein type inequality}?
%%\begin{figure}[!h]
%%\centering
%%\includegraphics[width=0.4\textwidth]{figures/onlinerates.png} 
%%%\caption{Start from a movie -- \emph{The Social Network}}
%%  \end{figure} 
%%
%}


%\frame{
%\frametitle{Averaging Process (Ruppert 1988; Y. 2010)}
%A second stage averaging process, following $s_{t+1}$ above
%\[ z_{t+1} = \frac{t}{t+1} z_t + \frac{1}{t+1} s_{t+1} \]
%with $z_0=s_0$.
%
%Note: 
%\begin{itemize}
%\item Averaging process speeds up convergence for various choices of $\gamma_t$ 
%\item One often choose $\gamma_t=c$ to track dynamics
%\item In this case, $z_t$ converges to $\hat{s}$ (population solution), with probability $1-\delta$, in the rate (optimal?) 
%\[ \|z_t - \hat{s}\|\leq O\left(\textcolor{red}{t^{-1/2} \cdot \lambda_2^{-2}(\Delta_0)} \cdot \log^{1/2} \frac{1}{\delta} \right) \]
%\end{itemize}
%}
%
%\subsection{Curl and Harmonics}

%\frame{
%\frametitle{Computation Issue of Curl and Harmonics}
%People may think that curl part seems easier to solve 
%$$\Delta_1^{up} \hat{y}^{(c)} = \delta_1^T \hat{y},$$ 
%where $\Delta_1^{up}=\delta_1^T \delta_1$. But \textcolor{red}{Forman's Ricci curvature}
%\[ \kappa(\Delta,e):= \#(\gamma\succ e) + 2 - \#(\mbox{parallel neighbors of $e$}) \]
%\begin{itemize}
%\item if $\kappa(\Delta,e)\geq 0$ for every $e$, then $\Delta$ is \textcolor{blue}{diagonal dominance} 
%\item any symmetric diagonal dominance matrix can be converted to graph Laplacian via 2-color covering 
%\item upper part $\Delta_1^{up}$ is less diagonal dominant as its Ricci curvature is $\#(\gamma \succ e) - \#(\mbox{neighbors of $e$}) <  \kappa(\Delta,e)$
%\end{itemize}
%}

%\frame{
%\frametitle{Harmonic ($Y^{(2)}$) and Triangular Curl ($Y^{(3)}$) }
%\begin{figure}[!h]
%\centering
%\includegraphics[width=0.45\textwidth]{figures/harmonic.pdf} 
%\includegraphics[width=0.45\textwidth]{figures/cyclic0.pdf}
%\caption{Left: example of $\hat{Y}^{(2)}$, harmonic; Right: example of $\hat{Y}^{(3)}$, curl.}
%  \end{figure} 
%}


%
%
%%\frame{
%%	\frametitle{Basic Problems in HodgeRank}
%%	\begin{itemize}
%%	\item sampling method for crowdsourcing 
%%	\subitem passive, active, random graph theory, etc.
%%	\item reliability of data: inconsistency
%%	\subitem outlier detection and robust ranking
%%	\item sequential or streaming data: online algorithms
%%	\subitem persistent homology, online ranking
%%	\end{itemize}
%%}
%
%
%%\frame{
%%	\frametitle{Triangular Transitivity vs. Consistency}
%%	\textbf{Triangular Transitivity subspace}: curl free 
%%	\[
%%	\{X\mid X_{ij}+X_{jk}+X_{ki}=0\text{ for all
%%	$3$-cliques}\}
%%	\]
%%	\begin{theorem}
%%	If the clique complex $\chi_G$ has first Betti number $\beta_1=0$, then triangular transitivity (local consistency) implies global consistency, i.e. $X_{ij}=s_i - s_j$ for some $s:V\to \R$. 
%%	\end{theorem}
%%	Note: this is the Arbitrage-free theory in finance: triangular arbitrage-free implies arbitrage-free.
%%}
%%
%%
%%\frame{
%%	\frametitle{Saari's Geometric Illustration}
%%	\begin{figure}
%%	\includegraphics[width=0.9\textwidth]{figures/Saari.jpg}
%%%	\caption{$Y^{(1)} is $l_2$-projection on the transitivity plane, compared to $l_1$-projection on }
%%	\end{figure}
%%}
%%
%
%
%


\frame{
\frametitle{Random Graph Models for Crowdsourcing}
\begin{itemize}
\item Recall that in crowdsourcing ranking on internet, 
\subitem unspecified raters compare item pairs randomly
\subitem online, or sequentially sampling
\item random graph models for experimental designs
\subitem $P$ a distribution on random graphs, invariant under permutations (relabeling)
\subitem \textcolor{red}{Generalized de Finetti's Theorem} [\textcolor{blue}{Aldous 1983, Kallenberg 2005}]: $P(i,j)$ ($P$ ergodic) is an uniform mixture of $$h(u,v)=h(v,u):[0,1]^2\to [0,1],$$ $h$ unique up to sets of zero-measure
\subitem \textcolor{red}{Erd\"{o}s-R\'{e}nyi}: $P(i,j) = P(edge) = \int_0^1\int_0^1 h(u,v)du dv=:p$ 
\subitem edge-independent process (Chung-Lu'06)
\end{itemize}
}


\frame{
\frametitle{Phase Transitions in Erd\"{o}s-R\'{e}nyi Random Graphs}
 \begin{figure}[!h]
\centering
\includegraphics[width=0.6\textwidth]{./figures/betti.png} 
  \end{figure} 
}

\frame{
\frametitle{Phase Transitions of Large Random Graphs}
 For an Erdos-Renyi random graph $G(n,p)$ with $n$ vertices and each edge independently emerging with probability $p(n)$, 

\begin{itemize}
\item (Erd\"{o}s-R\'{e}nyi 1959) \textcolor{red}{One phase-transition} for $\beta_0$
 \subitem $p<<1/n^{1+\epsilon}$ ($\forall \epsilon>0$), almost always disconnected
 \subitem $p>>log(n)/n$, almost always connected
  \item (Kahle 2009) \textcolor{red}{Two phase-transitions} for $\beta_k$ ($k\geq 1$)
\subitem  $p<< n^{-1/k}$ or $p>> n^{-1/(k+1)}$, almost always $\beta_k$ vanishes;
\subitem $n^{-1/k}<<p<<n^{-1/(k+1)}$, almost always $\beta_k$ is nontrivial
%\item may come from discrete Morse Theory
  \end{itemize}  
For example: with $n=16$, $75\%$ distinct edges included in $G$, then $\chi_G$ with high probability is connected and loop-free. In general, \textcolor{red}{$O(n\log(n))$} samples for connectivity and \textcolor{red}{$O(n^{3/2})$} for loop-free. 
}

%\frame{
%	\frametitle{Three sampling methods}
%	\begin{itemize}
%	\item \emph{Uniform sampling with replacement (i.i.d.)} ($G_0(n,m)$). 
%	\subitem \small{Each edge is sampled from the uniform distribution on $\binom{n}{2}$ edges, with replacement. This is a weighted graph and the sum of weights is $m$.}
%	\item \emph{Uniform sampling without replacement} ($G(n,m)$). 
%	\subitem \small{Each edge is sampled from the uniform distribution on the available edges without replacement. For $m\leq \binom{n}{2}$, this is an instance of the Erd\"{o}s-R\'{e}nyi random graph model $G(n,p)$ with $p=m/\binom{n}{2}$.}
%	\item \emph{Greedy sampling} ($G_\star(n,m)$). 
%	\subitem \small{Each pair is sampled to maximize the algebraic connectivity of the graph in a greedy way: the graph is built iteratively; at each iteration, the Fiedler vector is computed and the edge $(i,j)$ which maximizes $(\psi_{i} - \psi_{j})^{2}$ is added to the graph. }
%	\end{itemize}
%}
%
%\subsection{Fiedler Value Asymptotics}
%\frame{
%	\frametitle{Asymptotic Estimates for Fiedler Values [Braxton-Xu-Xiong-Y.'14]}
%	{\bf Key Estimates of Fiedler Value near Connectivity Threshold}.
%	\begin{align}
%	\label{eq:G0lam}
%	G_0(n,m)\colon \ & \frac{\lambda_2}{np} \approx a_1(p_0,n) := 1 - \sqrt{\frac{2}{p_0}}\sqrt{1-\frac{2}{n}} \\
%	\label{eq:Glam}
%	G(n,m)\colon \ &  \frac{\lambda_2}{np} \approx a_2(p_0,n):= 1 - \sqrt{\frac{2}{p_0}}\sqrt{1-p}
%	\end{align}
%	where $p_0:=2m/ (n \log n)\geq 1$, $p=\frac{p_0 \log n}{n}$ and 
%	$$a(p_0)=1 - \sqrt{2/p_0} + O(1/p_0), \ \ \ \mbox{ for $p_0\gg 1$.} $$
%}
%

%\frame{
%	\frametitle{Without-replacement as good as Greedy!}
%	\begin{figure}[t!]
%	\begin{center}
%	\includegraphics[width=0.6\columnwidth]{../osting/ACHA/ACHA/figs/64++}
%	\caption{A comparison of the Fiedler value, minimal degree, and estimates $a(p_0)$, $a_1(p_0)$, and $a_2(p_0)$ for graphs generated via random sampling with/without replacement and greedy sampling at $n= 64$.}
%	\label{icml-simulatedvalid}
%	\end{center}
%	\end{figure}
%}

%\frame{
%	\frametitle{Other sampling models [Xu et al. 2012]}
%	\begin{itemize}
%	\item Random $k$-regular graphs
%	\subitem Kim-Vu sandwich theorem/conjecture: coupling with Erd\"{o}s-R\'{e}nyi if edges are dense enough
%	\item Preferential-attachment random graphs
%	\subitem online but dependent (active) sampling
%	\subitem coupling with edge-independent process (Chung-Lu'06)
%	\item Geometric random graphs
%	\subitem ranking items from Euclidean feature space
%	\item Active sampling? 
%	\subitem Osting, Brune, and Osher, \emph{ICML} 2013
%	\subitem Osting, Xiong, Xu, and Y., 2014 
%	\end{itemize}
%}

%\subsubsection{Online Algorithms}
%
%\frame{
%\frametitle{Persistent Homology: online algorithm for topology tracking (e.g Edelsbrunner-Harer'08)}
% 
% \begin{columns} 
%\begin{column}{0.6\textwidth} 
%\begin{figure}[h]
%\centering
%	\includegraphics[width=0.7\textwidth]{figures/persistent.png} 
%	\caption{Persistent Homology Barcodes} 
%\end{figure}
%\end{column} 
%
%\begin{column}{0.4\textwidth} 
%\begin{itemize}
%\item vertice, edges, and triangles etc. sequentially added  
%\item online update of homology
%\item $O(m)$ for surface embeddable complex; and $O(m^{2.xx})$  in general ($m$ number of simplex)
%\end{itemize}
%\end{column} 
%\end{columns} 
%}
%


%
%\subsubsection{Robust Ranking}
%
%\frame{
%	\frametitle{Robust Ranking with Sparse Outliers}
%	For each $(i,j) \in E$, 
%	\begin{equation} 
%	y_{\alpha ij} = \beta_0 + \beta_i - \beta_j + z_{\alpha ij} 
%	\end{equation} 
%	where 
%	\begin{itemize} 
%	\item $\beta_V$: global ranking score on $V$ 
%	\item $\beta_0$: head-advantage (home- in NBA, white- in chess)
%	\item $z_{ij}$ error
%	\[ z_{\alpha ij} = \gamma_{\alpha ij} + \varepsilon_{\alpha ij} \]
%	\subitem[A0a] $\gamma_{\alpha ij}$ symmetric $p$-sparse (zero w.p. $p$ and median $0$)
%	\subitem[A0b] $\varepsilon_{\alpha ij}\sim \NN(0,\sigma^2/w_{ij})$ 
%	\end{itemize}
%}
%
%\frame{
%	\frametitle{Huber's LASSO [Xiong-Cheng-Y.'13, Xu-Xiong-Huang-Y.'13]}
%	\begin{itemize}
%	\item Robust ranking can be formulated as a Huber's LASSO problem (Gannaz'07, She-Owen'09, Fan-Tang-Shi'12)
%	\item Sparse outliers are sparse approximation of cyclic rankings (curl+harmonic)
%	\item Exact recovery is possible without Gaussian noise
%	\item Outlier detection is possible against Gaussian noise, provided
%	\subitem Irrepresentable condition (e.g. random graph)
%	\subitem Outliers have large enough magnitudes
%	\end{itemize}	
%	}
%%
%%\frame{
%%	\frametitle{Neyman-Scott'48: Incidental Paramters}
%%	A special case of Neyman-Scott'48:
%%	\begin{itemize}
%%	\item \textcolor{red}{Structural parameters}: global rating score $\beta$ which appears in \textcolor{red}{infinite} number of observations
%%	\item \textcolor{red}{Incidental parameters}: outliers $\gamma_{\alpha ij}$ which appears in \textcolor{red}{finite} (exactly once) number of observations
%%	\end{itemize}
%%	Maximum Likelihood generally suffers from:
%%	\begin{itemize}
%%	\item \textcolor{red}{Consistency} is destroyed with the presence of incidental parameters
%%	\item \textcolor{red}{Efficiency (asymptotic normality)} is lost even with consistency
%%	\end{itemize}
%%}
%
%%\frame{
%%	\frametitle{Huber's Robust Regression}
%%\begin{itemize}
%%\item Robust regression with Huber's loss
%%\[
%% \min_{\beta} \frac{1}{2} \sum_{(i,j)\in E}w_{ij} \rho_\lambda (y_{ij} - \beta_0 - (\beta_i-\beta_j )),
%%\]
%%where $\rho_\la(x)$ is Huber's loss function defined by
%%    \begin{equation*}
%%\rho_\lambda(x) =
%%    \left\{
%%    \displaystyle \begin{array}{ll}
%%        x^2/2, & \textrm{if $|x|\leq \lambda$}\\
%%        \lambda |x| - \lambda^2/2, & \textrm{if $|x|> \lambda$.}
%%    \end{array}
%%    \right.
%%    \end{equation*}
%%    \end{itemize}
%%}
%%
%%\frame{
%%	\frametitle{Equivalent Huber's LASSO}
%%	 (Gannaz'07, She-Owen'09, Fan-Tang-Shi'12)
%%	\[ \min_{\beta\in \Omega,\ga} \frac{1}{2} \|y-X\beta - \ga\|_{2,w}^2 + \la \|\ga\|_{1,w} + \eta \|\beta_V \|_2^2\]
%%	\begin{itemize}
%%	\item $\|\gamma\|_{1,w}$ for sparse outliers
%%	\item $X$ non full-rank, regularization $\|\beta_V\|_2^2$ for well-posedness 
%%\begin{equation*} \label{eq:design}
%%X := \left \{
%%\begin{array}{cc}
%%[\1,\grad], & \mbox{if $\beta^\ast_0\neq 0$ (under Assumption A3a)} ;\\
%%\grad, & \mbox{if $\beta^\ast_0 =0$ (under Assumption A3b)} .
%%\end{array}
%%\right.
%%\end{equation*}
%%Here $\1=[1,\ldots,1]^T\in R^{|E|}$, and the gradient matrix $\grad \in \R^{E\times V}$ is defined by $\grad(e=(i,j),i)=1$, $\grad(e=(i,j),j)=-1$, and otherwise zero. 
%%	\item For small enough $\eta>0$, it imposes the additional constraint $\sum_{i\in V} \beta_{i}=0$ to the solution
%%	\end{itemize}
%%}
%
%
%%\frame{
%%\frametitle{$\lambda=0$: $l_1$-norm ranking against pure Sparse Outliers}	
%%\begin{equation}
%%(L1): \ \ \min_{\beta} \|y-X\beta\|_{1,w}:=\sum_{(i,j)\in E}w_{ij} |y_{ij} - \beta_0 - (\beta_i-\beta_j)|,
%%\end{equation}
%%\begin{itemize}
%%\item Hochbaum-Levine 2006, Jiang-Lim-Y.-Ye 2011, Osting-Darbon-Osher 2012, 
%%\item The primal problem of L1 is a linear programming with a totally unimodular constraint matrix: integral $y\Rightarrow$ integral $\beta$ . 
%%\item The dual problem of L1 is a maximum-flow problem: bounded cyclic rankings with a maximal correlation with $y_{ij}$. 
%%\subitem Dual variables can be used to identify outliers. 
%%\end{itemize}
%%}
%
%
%
%\frame{
%	\frametitle{Exact Recover against pure Sparse Outliers}	
%\begin{theorem}[Xiong-Cheng-Y.'2013] Let $G(n,q)$ be an Erd\"{o}s-R\'{e}nyi
% Random Graph with $n$ nodes and each edge drawn independently with probability $q\in (0,1]$. \\
%(A) Suppose that paired comparison data $y$ is collected on $G(n,q)$ subject to the linear model with symmetric $p$-sparse outliers ($p\in [0,1]$). Then with probability tending to one the L1 solution exactly recovers the global ranking $\beta^\ast$ if 
%\[ p \gg O\left( \sqrt{\frac{\log n }{ n q} } \right). \] 
%\end{theorem}
%Note: no method can recover if 
%\[ p \ll O\left( \frac{1 }{\sqrt{ n q} } \right). \]
%}
%
%%\frame{
%%	\frametitle{Exact Recover against pure Sparse Outliers}	
%%\begin{theorem}[continued] (B) There exists a setting for measurements and symmetric $p$-sparse outliers such that no method will exactly recover the global ranking with high probability if 
%%\[ p \ll O\left( \frac{1 }{\sqrt{ n q} } \right). \]
%%\end{theorem}
%%}
%
%
%%\frame{
%%	\frametitle{Basic Assumptions}
%%	\begin{itemize}
%%	\item[A1.] $G$ weakly connected
%%	\item[A2.] $\sum_{i\in V}\beta_i=0 $ 
%%	\item[A3a.] If $\beta_0\neq 0$, $\sum_{(i,j)\in E} w_{ij} = \sum_{(j,i)\in E} w_{ji}$ 
%%	\item[A3b.] If $\beta_0 = 0$, undirected graph with skew-symmetric data $y_{ji} = - y_{ij}$
%%	\end{itemize}
%%	\begin{equation} 
%%	y = X \beta + z
%%	\end{equation}	
%%}
%
%
%%\frame{
%%	\frametitle{Sparsity of Outliers saves...}
%%	Fortunately, sparsity of outliers may lead to partial consistency 
%%	\begin{itemize}
%%	\item \textcolor{red}{Sparse large outliers $S_0$}: $m_0=m p_0$ outliers 
%%	\[ |\gamma_{S_0}|\geq O( \sigma\sqrt{\log m}) \]
%%	\item \textcolor{red}{Nuisance outliers $S_1$}: $m(1-p-p_0)$ outliers 
%%	\[ |\gamma_{S_1}|\leq O(\sigma) \]
%%	\item Otherwise: $mp$ clean observations
%%	\end{itemize}
%%}
%%
%%\frame{
%%	\frametitle{Outlier Detection LASSO}
%%\begin{equation} \label{eq:oLasso}
%%\min_{\ga} \frac{1}{2} \| \proj_{\Gamma} W^{1/2} y - \proj_{\Gamma} W^{1/2} \ga \|_2^2 + \la \|\ga\|_{1,w}.
%%\end{equation} 
%%\begin{itemize}
%%\item $\Gamma\subseteq l^2(E)$ and $\Gamma \perp col(W^{1/2} X)$.
%%\item For Erd\"{o}s-R\'{e}nyi random graph $G(n,q)$, $dim(\Gamma)/dim(l^2(E)) \sim 1 - 1/\log n \to 1$. 
%%\item Let $\Psi$ be an $l$-by-$|E|$ ($0< l \leq |E|$) projection matrix from $l^2(E)$ into $\Gamma$.
%%\end{itemize}
%%}
%%
%%
%%\frame{
%%	\frametitle{Partial Sign Consistency for Outlier Detection}
%%	\begin{theorem}[Sign Consistency, Xiong-Cheng-Y.'2013]
%%\[ \sign(\hat{\ga}_{S_0})=\sign(\ga_{S_0}^\ast) \ \ \ \mbox{with $\hat{\ga}_{k}=0$ for $k\not\in S_0$} \]
%%if the following holds and $\lambda \geq O(\sigma \sqrt{\log m})$
%%\begin{itemize}
%%\item (C1: Restricted Eigenvalue)
%%\[ \Lambda_{\min} \left(\frac{1}{l} \Psi_S^T \Psi_S \right) = C_{\min} > 0. \]
%%\item (C2: Irrepresentability) For some constant $\eta\in (0,1]$,
%%\[ \| W_{S^c}^{-1/2} \Psi^T_{S^c} \Psi_{S} (\Psi^T_{S} \Psi_{S})^{-1} W_S^{1/2} \sign (\ga^\ast_S) \|_\infty \leq 1 -\eta. \]
%%%(a) for some constant $\eta\in (0,1]$,
%%%\[ \| W_{S^c}^{-1/2} \Psi^T_{S^c} \Psi_{S} (\Psi^T_{S} \Psi_{S})^{-1} W_S^{1/2} \sign (\ga^\ast_S) \|_\infty \leq 1 -\eta; \]
%%%or (b) slightly stronger
%%%\[ \| W_{S^c}^{-1/2} \Psi^T_{S^c} \Psi_{S}(\Psi^T_{S} \Psi_{S})^{-1} W_S^{1/2} \|_\infty \leq 1 -\eta; \]
%%\item (C3: Large Outlier)  $\ga_{min} :=\min_{i\in S_0} |\ga^\ast_i| \gg O(\la)$
%%\end{itemize}
%%\end{theorem}
%%}
%%
%%\frame{
%%	\frametitle{$l_2$-consistency for structural parameters}
%%	\begin{theorem}[$l_2$-Consistency]
%%	Moreover
%%	\begin{itemize}
%%	\item Sparsity:
%%	\[  s=m(1-p) \ll O\left(\sqrt{\frac{mp}{n}}\right)\Rightarrow p \gg 1 - O\left( \frac{1}{\sqrt{mn}}\right)\]
%%	\item Conductance bound: $\Pr(\lambda_{1}^{-1}(\hat{\Delta}_0) \geq \kappa_n) \to 0$
%%	\subitem General graphs with diameter $D$: $\kappa_n \leq Dn$
%%	\subitem Erd\"{o}s-R\'{e}nyi: $\kappa_n \leq n \log n$
%%%	\item Large outliers:
%%%	\[ \min_{i\in S_0} |\ga^\ast_i| \geq O(\sigma \sqrt{\log m}) \]
%%	\end{itemize}
%%	Then for small $\mu>0$, 
%%	\[ \| \hat{\beta} - \beta^\ast \|_2 \leq O\left (\sigma \sqrt{\frac{\kappa_n\log m}{mp}} \right) \]
%%	\end{theorem}
%%	
%%	}
%%
%%\frame{
%%	\frametitle{Control $\kappa_n$: active sampling}
%%	\begin{itemize}
%%	\item $\kappa_n$ is an upper bound for inverse smallest nonzero eigenvalue 
%%	\[ \Pr(\lambda_{1}^{-1}(\hat{\Delta}_0) \geq \kappa_n) \to 0 \]	
%%	\item Ostings-Brune-Osher'2013
%%	\subitem Fisher information maximization
%%	\subitem greedy algorithm to find graphs with smallest $\kappa_n$
%%	\end{itemize}
%%	}
%
%%\frame{
%%	\frametitle{$\lambda = \infty$: Pure Gaussian Noise}
%%	\begin{equation} 
%%	y_{ij} = \beta_0 + \beta_i - \beta_j + \varepsilon_{ij} 
%%	\end{equation} 
%%	where Gauss-Markov theorem tells us that if under A3a, 
%%\[ \frac{1}{m} X^T W X = 
%%\left(
%%\begin{array}{cc}
%%1 & 0  \\
%%0 & \frac{1}{m} \De_0 
%%\end{array}
%%\right) \to 
%%\left(
%%\begin{array}{cc}
%%1 & 0 \\
%%0 & \bar{\De}_0 
%%\end{array}
%%\right) =: \bar{\Sigma}, \ \ \ \ \ m=|E|
%%\]
%%then 
%%\begin{eqnarray}
%%(L2): & \displaystyle \min_{\beta\in \Omega} \|y-X\beta\|^2_{2,w}:=\sum_{(i,j)\in E} w_{ij} (y_{ij} - \beta_0 - (\beta_i - \beta_j))^2, &
%%\end{eqnarray}
%%has the minimal norm least square solution $\sqrt{m} (\hat{\beta}-\beta)\to \NN(0,\bar{\Sigma})$. 
%%}
%

\frame{
	\frametitle{Some reference}
	\begin{itemize}
	\item Random graph sampling models: Erd\"{o}s-R\'{e}nyi and beyond
	\subitem Xu, Jiang, Yao, Huang, Yan, and Lin, \emph{ACM Multimedia}, 2011, IEEE Trans Multimedia, 2012
	\item Online algorithms
	\subitem Xu, Huang, and Yao, \emph{ACM Multimedia} 2012
	\item $l_1$-norm ranking
	\subitem Osting, Darbon, and Osher, 2012
	\item Robust ranking: Huber's Lasso
	\subitem Xiong, Cheng, and Yao, 2013
	\subitem Xu, Xiong, Huang,  and Yao, \emph{ACM Multimedia} 2013
	\item Active sampling
	\subitem Osting, Brune, and Osher, \emph{ICML} 2013
	\subitem Osting, Xiong, Xu, and Yao, 2014
	\end{itemize}
}
%%\frame{
%%\frametitle{An Intuition from Random Matrix Theory}
%% Concentration of eigenvalues (\textcolor{blue}{Chung-Radcliffe 2011})
%% \[ |\lambda_i (\tilde{\Delta}_0) - \lambda_i (\bar{\Delta}_0) | \leq  O\left(\sqrt{np \log\frac{n}{\delta}}\right) \]
%%where
%% \[
%% \bar{\Delta}_0(i,j) = np I_n - p e e^T = \left\{
%% \begin{array}{lr}
%% -p, & i\neq j \\
%% (n-1)p, & i=j
%% \end{array}
%% \right. 
%% \]
%% has one eigenvalue $0$, and one eigenvalue $np$ of multiplicity $n-1$
%%\begin{itemize}
%% \item $p>>n^{-1}\log n$, almost always large eigenvalues $np=\Omega(1)$;   
%%\item $p<<n^{-1-\epsilon}$, almost always small eigenvalues $np=o(1)$; 
%% \end{itemize}
%%}
%%
%%\frame{
%%\frametitle{For 1-Laplacian ...}
%% \[
%% \tilde{\Delta}_1^{(l)}(ij,kl) =\delta_0\circ\delta_0^\ast=\left\{
%% \begin{array}{lr}
%% 2X_{ij} \to \textcolor{red}{2p}, & \{i,j\}=\{k,l\} \\
%%  \xi^{(l)}_{ij,kl} X_{ij} X_{jk} \to \textcolor{red}{ \xi^{(l)}_{ij,kl} p^2}, & \textrm{otherwise}
%% \end{array}
%% \right. 
%% \]
%% where \textcolor{blue}{lower}-coincidence number $\xi^{(l)}_{ij,kl} =\pm 1$ if $|\{i,j\} \cap \{k,l\}|=1$ and $0$ otherwise. 
%%  \[
%% \tilde{\Delta}_1^{(u)}(ij,kl) =\delta_1^\ast\circ\delta_1=\left\{
%% \begin{array}{lr}
%% \sum_{ij\tau\in T}  X_{ij} X_{j\tau} X_{\tau i}  \to \textcolor{red}{\frac{(np)(np^2)^n}{\log np^2}}, & ij = kl \\
%%  \xi^{(u)}_{ij,kl} X_{ij} X_{jk} X_{ki} \to \textcolor{red}{  \xi^{(u)}_{ij,kl} p^3}, & \textrm{otherwise}
%% \end{array}
%% \right. 
%% \]
%% where \textcolor{blue}{upper}-coincidence number $\xi^{(u)}_{ij,kl} =\pm 1$ if $|\{i,j\} \cup \{k,l\}|=3$ and $0$ otherwise. 
%% 
%% \begin{itemize}
%% \item \textcolor{blue}{Forman (2003)}: \textcolor{red}{$Ric_{\bar{\Delta}_1}$(ij) = diagonal - sum of abs(off-diag)}
%% \item $p<<n^{-1}$ or $p>>n^{-1/2}$, $\bar{\Delta}_1$ \textcolor{blue}{strongly diagonal dominant}
%% \end{itemize}
%%}
%


%\section{Application}
%\subsection{Netflix Example}
%\frame{
%	  \frametitle{Choose 6 Netflix Movies with Dynamic Drifts}
%	\begin{figure}
%	\includegraphics[width=0.8\textwidth]{figures/nflix6.jpg}
%	\end{figure}
%}
%
%\frame{
%	  \frametitle{Model Selection by Curls}
%	\begin{figure}
%	\includegraphics[width=0.9\textwidth]{figures/nflix6_comp.jpg}
%	\end{figure}
%	\tiny{ MRQE: Movie-Review-Query-Engine (http://www.mrqe.com/)}
%}
%


%\subsection{Online Video Quality Evaluation}
%\frame{
%\frametitle{Data Description}
%\begin{itemize}
%\item Dataset:  LIVE Database
%\item 10 different reference videos and 15 distorted versions of 
%each reference, for a total of 160 videos.
%\item 32 rounds of complete comparisons are collected from 209 observers in lab. Because each round needs 1200 paired comparisons, the total number of comparisons for 32 rounds is $38400 = 32 \times 1200$.
%\item \textcolor{brown}{Note}: we do not use the subjective scores in LIVE, 
%we only borrow the video sources it provides.
%\end{itemize}
% \begin{figure}[!h]
%\centering
%\includegraphics[width=0.2\textwidth]{figures/System_ScreenSaver.png} 
%\caption{Data collected from PKU junior undergraduates.}
%  \end{figure} 
%
%}
%
%\frame{
%\frametitle{HodgeRank with Complete Data}
% \begin{figure}[!h]
%\centering
%\includegraphics[width=0.6\textwidth]{figures/complete10.png} 
%\caption{Angular Transform and Uniform models are the best two.}
%  \end{figure} 
%}
%
%\frame{
%\frametitle{Sampling Efficiency}
%\begin{figure}[!h]
%\centering
%\includegraphics[width=0.5\textwidth]{figures/exp3.png} 
%\includegraphics[width=0.5\textwidth]{figures/table3.png} 
%%\caption{Left: with just $5\%$ samples, the $\chi_G$ is connected and loop-free w.h.p.; Right: high accuracy after 100 bootstraps}
%  \end{figure} 
%}
%
%\frame{
%\frametitle{Convergence of Online Learning Algorithms}
%\begin{figure}[!h]
%\centering
%\includegraphics[width=0.9\textwidth]{figures/online_s0=0.png} 
%%\caption{Start from a movie -- \emph{The Social Network}}
%  \end{figure} 
%}

%\frame{
%\frametitle{Discussions on HodgeRank with random graphs}
%\begin{itemize}
%\item \textcolor{red}{Erd\"{o}s-R\'{e}nyi} random graphs give the simpliest sampling scheme, comparable to \textcolor{blue}{I.I.D.} sampling in machine learning
%\item General random graphs (unlabeled) can use nonparametric models derived from \textcolor{red}{generalized de Finetti's theorem} (Bickel, Chen 2009)
%\item For computational concern, consider random graphs with small condition numbers, e.g. \textcolor{red}{expanders} 
%\item For balancing concern, consider \textcolor{red}{random $k$-regular graphs}
%\item \textcolor{red}{Markov sampling} (Aldous, Vazirani 1990; Smale, Zhou 2007)  
%\item \textcolor{red}{Concentration inequalities with dependent random variables} for high-dim Laplacians
%\end{itemize}
%}

%\frame{
%\frametitle{Some Reference}
%\begin{itemize}
%\item Jiang, Lim, Yao, and Ye, \emph{Mathematical Programming}, 127(1): 203-244, 2011
%\item Candogan, Menache, Ozdaglar, and Parrilo, \emph{Mathematics of Operational Research}, 36(3): 474-503, 2011
%\item Ma, Morel, Osher, and Chien, \emph{Tech Report CAM11-13}, 2011
%\item Tran, N. M. "Pairwise ranking: choice of method can produce arbitrarily different rank order", arXiv:1103.1110v1 [stat.ME], 2011
%\item Xu, Jiang, Yao, Huang, Yan, and Lin, \emph{ACM Multimedia}, 2012
%\end{itemize}
%}


%\frame{
%	\frametitle{Applications of Hodge Decomposition}
%	\begin{itemize}
%	\item Boundary Value Problem (Schwarz, Chorin-Marsden'92)
%	\item Computer vision
%	\subitem Optical flow decomposition and regularization (Yuan-Schn\"{o}rr-Steidl'2008, etc.)
%	\subitem Retinex theory and shade-removal (Ma-Morel-Osher-Chien'2011)
%	\subitem Relative attributes (Fu-Xiang-Y. et al. 2014)
%	\item Sensor Network coverage (Jadbabai et al.'10)
%	\item Statistical Ranking or Preference Aggregation (Jiang-Lim-Y.-Ye'2011, etc.)
%	\item Decomposition of Finite Games (Candogan-Menache-Ozdaglar-Parrilo'2011)
%	\end{itemize}
%}

%\subsection{Game Theory}
%%\frame{
%%\frametitle{Ranking in Economics: Utility and Voting}
%%  \begin{figure}[!h]
%%\centering
%%\includegraphics[width=0.8\textwidth]{figures/game.png} 
%%%\caption{Clicks implies preference}
%%  \end{figure} 
%%}
%
\section[Game Theory]{Hodge Theory for Games}
\subsection{Flow Representation for Finite Games}
\frame{
\frametitle{Multiple Utility Flows  for Games}
\begin{figure}[!h]
%\centering
\includegraphics[width=0.3\textwidth]{./figures/battleSex_mat.pdf}  
\includegraphics[width=0.3\textwidth]{./figures/battleSex.pdf} 
\end{figure}
Extension to multiplayer games: $G=(V,E)$ \\
\begin{itemize}
\item $V=\{(x_1,\ldots,x_n)=:(x_i,x_{-i})\}=\prod_{i=1}^n S_i$, $n$ person game;
\item undirected edge: $\{(x_i,x_{-i}), (x_i^\prime,x_{-i})\}= E$ 
\item each player has utility function $u_i(x_i,x_{-i})$; 
\item Edge flow (1-form): $u_i(x_i,x_{-i})-u_i(x^\prime_i,x_{-i})$
\end{itemize}
}

\frame{
\frametitle{Nash and Correlated Equilibrium}
 $\pi(x_i, x_{-i})$, a joint distribution tensor on $\prod_i S_i$, satisfies $\forall x_i,x^\prime_i$,
\[ \sum_{x_{-i}} \pi(x_i,x_{-i}) (u_i(x_i, x_{-i}) - u_i(x^\prime_i,x_{-i}))\geq 0, \]
i.e. expected flow ($\E[\cdot|x_i]$) is nonnegative. Then, 
\begin{itemize}
\item tensor $\pi$ is a \textcolor{red}{correlated equilibrium} (CE, Aumann 1974);
\item if $\pi$ is a rank-one tensor, 
\[\pi(x)=\prod_i \mu(x_i) ,\] 
then it is a \textcolor{red}{Nash equilibrium} (NE, Nash 1951);
\item fully decided by the edge flow data.
\end{itemize}
}



%\frame{
%	\frametitle{What is a correct notion of Equilibrium?}
%	\begin{itemize}
%	\item Players are never independent in reality, e.g. Bayesian decision process (Aumman'87)
%	\item Finding NE is NP-hard, e.g. solving polynomial equations (Sturmfels'02, Datta'03)
%	\item Finding CE is linear programming, easy for graphical games (Papadimitriou-Roughgarden'08)
%	\item Some natural learning processes converges to CE (Foster-Vohra'97)
%	\end{itemize}
%	}

%\frame{
%	\frametitle{Low Rank CE Tensors}
%	\begin{itemize}
%	\item CE contains the convex hull of NE, nonnegative tensor rank $\sim \#(NE)$ (e.g. 2 pure NE in BoS)
%	\end{itemize}
%	\begin{theorem}[Landsberg-Manivel'03, Raicu]
%	A tensor is of rank $\leq 2$ if and only if all its matrix \textcolor{red}{flattenings} are of rank $\leq 2$. 
%	\end{theorem}
%	\begin{theorem}[Allman-Rhodes-Sturmfels-Zwiernik'13]
%	A \textcolor{blue}{nonnegative} tensor has nonnegative rank $\leq 2$ if and only if it is of rank $\leq 2$ and 
%	\textcolor{red}{supermodular}. 
%	\end{theorem}
%	\textcolor{red}{Open:} can we find low rank nonnegative tensor approximations subject to linear inequality constraints?
%	}
%
%\frame{
%	\frametitle{Another simplification: Graphical Games}
%	\begin{itemize}
%	\item $n$-players live on a network of $n$-nodes
%	\item player $i$ utility only depends on its neighbor players $N(i)$ strategies 
%	\item correlated equilibria allows a concise representation with parameters linear to the size of the network (Kearns et al. 2001; 2003)
%	\[ \pi(x) = \frac{1}{Z} \prod_{i=1}^n \psi_i(x_{N(i)}) \]
%	\subitem this is not rank-one, but \textcolor{red}{low-order interaction}
%	\subitem reduce the complexity from $O(e^{2^n})$ to $O(n e^{2^d})$ ($d=\max_i |N(i)|$) 
%	\subitem polynomial algorithms for CE in \emph{tree} and \emph{chodal} graphs.
%	\end{itemize}
%	}
%
%
\subsection{Hodge Decomposition of Finite Games}

\frame{
\frametitle{Hodge Decomposition of Finite Games}
\begin{theorem}[Candogan-Menache-Ozdaglar-Parrilo,2011]
Every finite game admits a unique decomposition:
\[ \mbox{Potential Games} \oplus \mbox{Harmonic Games} \oplus \mbox{Neutral Games} \] 
\end{theorem}
Furthermore:
\begin{itemize}
\item Shapley-Monderer Condition: Potential games $\equiv$ quadrangular-curl free 
\item Extending $G=(V,E)$ to complex by adding quadrangular cells, harmonic games can be further decomposed into \textcolor{red}{(quadrangular) curl games}
%\begin{figure}[!h]
%\centering
%\includegraphics[width=0.9\textwidth]{figures/hodgegame.png} 
%%\caption{Start from a movie -- \emph{The Social Network}}
%  \end{figure} 
\end{itemize}
}

\frame{
	\frametitle{Bimatrix Games}
	 For bi-matrix game $(A,B)$,
	\begin{itemize}
	\item  potential game is decided by $((A+A')/2,(B+B')/2)$ 
%	\subitem pure Nash equilibria are the set of local maxima
%	\subitem Correlated equilibria: $\supseteq$the convex hull of such maxima (e.g. Neyman'97)
	\item harmonic game is zero-sum $((A-A')/2,(B-B')/2)$
%	\subitem only mixed Nash equilibria
	\item Computation of Nash Equilibrium:
	\subitem each of them is tractable
	\subitem however direct sum is NP-hard
	\subitem approximate potential game leads to approximate NE
%	\item a special case of Leontief Equilibrium for Exchange Market 
	\end{itemize}
}


\frame{
\frametitle{What Does Hodge Decomposition Tell Us?}
Christos Papadimitriou: best response players might experience
\[ \mbox{transient potential games} + \mbox{periodic equilibrium} \]
\begin{figure}[!h]
\centering
\includegraphics[width=0.8\textwidth]{figures/history-cycle} 
%\caption{Start from a movie -- \emph{The Social Network}}
  \end{figure} 
}





%\frame{
%\frametitle{Example: Hodge Decomposition of Prisoner's Dilemma}
%\begin{figure}[!h]
%\centering
%\includegraphics[width=0.9\textwidth]{figures/hodgegame.png} 
%%\caption{Start from a movie -- \emph{The Social Network}}
%  \end{figure} 
%  Note: Shapley-Monderer Condition $\equiv$ Harmonic-free $\equiv$ quadrangular-curl free
%}
%
%

%\section{Summary}
\frame{
\frametitle{Summary}
Hodge Decomposition for Social Choice:
\begin{itemize}
\item Generalized Borda Count
\item Borda profile in gradient flow $\Rightarrow$ global ranking or utility function
\item Condorcet profile in cyclic ranking, triangular cyclic or harmonic rankings
\end{itemize}
for Game theory with multiple utility functions:
\begin{itemize}
\item Potential games in gradient flow 
\item Harmonic games in cycles
\item CE and NE are preserved, tractable in some settings
\end{itemize}
in Computer Vision: optical flow decomposition, subjective visual attributes, and more are coming ...
}


%\frame{
%\frametitle{Acknowledgement}
%\begin{itemize}
%\item Multimedia group:
%\subitem \emph{\textcolor{red}{Qianqian Xu}}, Postdoc at BICMR, PKU
%\subitem \emph{Qingming Huang}, GUCAS; \emph{Tingting Jiang}, PKU
%\item Methodology: 
%\subitem \emph{\textcolor{red}{Jiechao Xiong}}, Stat PhD student in PKU
%\subitem \emph{Braxton Ostings}, UCLA; \emph{Xi CHen}, NYU
%\item Computer vision group:
%\subitem \emph{\textcolor{red}{Yanwei Fu}}, EECS PhD student at University of London
%\subitem \emph{Tao Xiang}, \emph{Tim Hospedales}, \emph{Shaogang Gong}, QMUL
%\subitem \emph{Yizhou Wang}, PKU
%\item Other colleague
%\subitem  \emph{\textcolor{red}{Lek-Heng Lim}}, \emph{Stan Osher}, \emph{Yinyu Ye}, \emph{Sayan Mukherjee}, \emph{Pablo Parrilo} %, \emph{Lie Wang} (MIT), Art Owen (Stanford), \emph{Anil Hirani} (UIUC)
%%\item Grants: 
%%\subitem National Basic Research Program of China (973 Program), NSFC, Microsoft Research - Asia, Professorship in the 100-Talent Program at PKU
%\end{itemize}
%}
%
\end{document}

